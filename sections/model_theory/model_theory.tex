\documentclass[../../main.tex]{subfiles}
\begin{document}
The aim of this chapter is to give an introduction to the basic tools of model theory with which we will prove the \hyperref[up-lowenheim-skolem]{LÃ¶wenheim-Skolem Theorem}.
This theorem, divided into two parts, is dependent on the \hyperref[choice-axiom]{Axiom of Choice}, 
hence we will later use it to show that \textbf{AC} implies the existence of a group structure on all non-empty sets.

We were already concerned with axiomatizations in the previous chapters, however we will formalize these notions some more here.
The set theory axioms outlined in Chapter \ref{preliminaries} still hold true, 
but we will discover more about what is and is not true in for example group theory or other algebraic structures.
We start the treatment of model theory with the motivating example of ``Ehrenfeucht-Fra\"isse games'', 
exemplifying how the field relates to the linear orderings from Chapter \ref{orderings}.
The impatient or familiar reader however may skip this section without missing any necessary theory.

\section{Ehrenfeucht-Fra\"isse Games}
Let us suppose we are given two linear orderings, based on which we define a two player game.
Player I is called \textit{spoiler} and starts by picking a point on one of the two orderings.
If they pick an element of $A$ we call this $a_1$ and if they pick an element of $B$ we call it $b_1$.
After the spoiler has picked their point, player II will pick a point on the other linear ordering. 
We call player II \textit{duplicator}.\footnote{The names ``spoiler'' and ``duplicator'' were coined by Joel Spencer.\cite[\S 6]{Wil24}
The literature \cite{Ros82} this section of the text is mainly based on uses ``Player I'' and ``Player II'' instead.}
Say spoiler picked $a_1$ in $A$, duplicator then has to pick some element $b_1$ of $B$.

The spoiler and duplicator go back and forth picking points on the linear orderings for a predetermined amount of turns $n$.
Spoiler always gets to choose the ordering they pick a point on and duplicator has to pick something on the other ordering.
The second player, duplicator, wins if the elements $a_1,\ldots,\, a_n$ are in the same order with respect to $A$ as the elements $b_1,\ldots,\, b_n$ are with respect to $B$.
Spoiler wins if duplicator loses, if the elements are not in the same order. 
This is how a single play of an \textit{Ehrenfeucht-Fra\"isse game}, also called a \textit{Back-and-forth game}, in $n$ turns is played out. \cite[\S 6.1]{Ros82}

\begin{example}\label{game-example-1}
    We will go through the play of a game with $3$ steps. 
    Let $A = \mathbb{Q}$ and $B=\mathbb{Z}$ under the usual order be the two linear orderings that are played on.
    
    Spoiler starts and picks the point $a_1 = 0$ in $\mathbb{Q}$. Duplicator on their turn also picks the point $b_0 = 0$ but in $\mathbb{Z}$.
    On the next turn spoiler picks $a_2 = 1$ in $\mathbb{Z}$, duplicator again matches this and picks $b_2 = 1$ in $\mathbb{Q}$.
    Now however spoiler can and does pick $b_3$ in $\mathbb{Q}$ to be $\frac{1}{2}$. 
    This is not possible for duplicator to match since they are now confined to picking a point $a_3$ in $\mathbb{Z}$.
    Hence no matter what point duplicator picks to be $a_3$, they will lose.
\end{example}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[scale=2]
        % draw nodes for game stages 
        \draw[densely dotted] (0,   0) -- (0,   0.2) node[draw, solid, above, align=center] {I,  $a_1$};
        \draw[densely dotted] (1,   0) -- (1,   0.2) node[draw, solid, above, align=center] {I,  $a_2$};
        \draw[densely dotted] (2,   0) -- (2,   0.2) node[draw, solid, above, align=center] {II, $a_3$};
        \draw (2,   0.2) node[draw, cross out, above, align=center] {II, $a_3$};
        \draw[densely dotted] (0,  -2) -- (0,  -1.7) node[draw, solid, above, align=center] {II, $b_1$};
        \draw[densely dotted] (1,  -2) -- (1,  -1.7) node[draw, solid, above, align=center] {II, $b_2$};
        \draw[densely dotted] (0.5,-2) -- (0.5,-1.2) node[draw, solid, above, align=center] {I,  $b_3$};

        % draw both coordinate axes
        \foreach \y/\ytext in {0/A = \mathbb{Z}, -2/B = \mathbb{Q}} {
            \draw[thick, <->] (-1.5, 0 + \y) node[draw, left = 20] {$\ytext$} -- (2.5, 0 + \y);
            \draw[thick] (0,-0.1 + \y) -- (0, 0.1 + \y);
            \foreach \x in {-1, 0,...,2} {
                \draw (\x,-0.05 + \y) -- (\x, 0.05 + \y) node[below = 10] {$\x$};
            }
        }

        % draw extra ticks for Q
        \foreach \x/\xtext in {-0.5/-\frac{1}{2}, 0.5/\frac{1}{2}, 1.5/\frac{3}{2}} {  
            \draw (\x,-0.05 - 2) -- (\x, 0.05 - 2) node[below = 10] {$\xtext$};
        }
    \end{tikzpicture}
    \caption{Example \ref{game-example-1} illustrated.
    Points \textit{spoiler} picked are prefixed by ``I'', points \textit{duplicator} picked are prefixed by ``II''.
    It can be seen that duplicator is not able to pick a suitable element for $b_3$ in $\mathbb{Z}$ such that $a_1$, $a_2$ and $a_3$ have the same order as $b_1$, $b_2$ and $b_3$.}
\end{figure}

It should be clear that in order for spoiler to win, they need to exploit the differences of the linear orders in play.
In the example above spoiler can alway pick their first two elements to be $a_1$ and $a_2$ in $\mathbb{Z}$ in a way where $a_2$ is the immediate successor of $a_1$.
Then, because $\mathbb{Q}$ is dense, no matter which elements duplicator picks to be $b_1$ and $b_2$, spoiler can pick $b_3$ such that $b_1 < b_3 < b_2$.
As $a_2$ is the immediate successor of $a_1$, there exists no element in $\mathbb{Z}$ satisfying  $a_1 < a_3 < a_2$.

This is called a \textit{winning strategy} for spoiler.
A winning strategy for duplicator would be the converse, where duplicator can react according to every possible move by spoiler and still win.
For duplicator to have a winning strategy, the linear orderings should be \textit{similar} in some sort of way, 
in fact the existence of a winning strategy by duplicator is a type of equivalence in itself.
Such a winning strategy shown in the example below, where we play a game with two dense orderings.

\begin{example}\label{game-example-2}
    We play an Ehrenfeucht-Fra\"isse game in $n$ rounds.

    Let $A = \mathbb{R}$ and $B=\mathbb{Q}$ under the usual order.
    We can define a winning strategy for duplicator inductively.
    Duplicator then picks a point according to one of the following cases on an arbitrary turn $i$:
    \begin{enumerate}
        \item It is the first turn and spoiler picks $a_1 \in A$.
        
        Duplicator then picks $b_1 = 0$.
        \item Spoiler picks $a_i \in A$ such that $a_j < a_i < a_k$ holds for some $a_j,\, a_k \in A$.
        
        It can be assumed without loss of generality that $a_j$ and $a_k$ are the respectively largest and smallest points for which this property holds.
        Then there exist corresponding $b_j,\, b_k \in B$ with $b_j < b_k$. Hence duplicator can choose $$b_i = \frac{b_k - b_j}{2}.$$
        \item Spoiler picks $a_i \in A$ such that $a_i$ is either larger or smaller than all $a_k$ for $k < i$.
        
        Duplicator can pick 
        \begin{align*}
            b_i = b_s - 1 && \text{or} && b_i = b_l + 1
        \end{align*}
        in $B$ where $b_s$ and $b_l$ are the smallest and largest elements of $\left\{b_k \,\vert\, k < n\right\}$ respectively.
    \end{enumerate}    
    Since $\mathbb{Q}$ is a proper subset of $\mathbb{R}$ the same strategy works if spoiler chooses an element $b_i$ in $B = \mathbb{Q}$.
    The strategy for the second turn follows immediately from the third case. 
\end{example}

With this example in mind we now formally define the play of an Ehrenfeucht-Fra\"isse game and what it means for duplicator to have a winning strategy.

\begin{definition}[Ehrenfeucht-Fra\"isse Game]\cite[Definition 6.2]{Ros82}
    Let $A$ and $B$ be linear orderings and let $n \in \mathbb{Z}^+$ be a fixed positive integer.
    Then a \textit{play of an Ehrenfeucht-Fra\"isse game} $EF_n(A,\, B)$ is defined as an ordered sequence with $2n$ elements.
    For each positive integer $k \leq n$ player I, \textit{spoiler}, chooses an element in either $A$ or $B$.
    Player II, \textit{duplicator}, then chooses an element of the ordering spoiler did not pick.
    We denote an element at the $k$th turn as $a_k$ if it was picked from $A$ and $b_k$ if it was picked from $B$.

    We say that duplicator has won a play of the game $EF_n(A,\, B)$ if for all positive integers $i,\, j \leq n$
    $$a_i <_A a_j \iff b_i <_B b_j$$
    with respect to the linear orders $<_A$ and $<_B$ of $A$ and $B$.
    We say that spoiler has won a play of the game if duplicator did not win.

    We say that there exists \textit{winning strategy of duplicator} if there exists a sequence of functions $f_1,\ldots,\,f_n$,
    which fulfills the following requirements:
    \begin{enumerate}[label=(\roman*)]
        \item The domain of each $f_k$ is the set of all ordered $k$-tuples with elements in $A \cup B$;
        \item For elements $c_1,\ldots,\, c_k \in A \cup B$, representing the first $k$ moves by spoiler, $f_k$ satisfies
              \begin{align*}
                    &f_k(c_1,\ldots,\, c_k) \in A \ \text{if} \ c_k \in B \ \text{and}\\
                    &f_k(c_1,\ldots,\, c_k) \in B \ \text{if} \ c_k \in A.
              \end{align*}
        \item For elements $c_1,\ldots,\, c_k \in A \cup B$, $f_k$, $a_k$ and $b_k$ are defined as
              \begin{align*}
                a_k = \begin{cases}
                        c_k \ &\text{if} \ c_k \in A \\
                        f_k(c_1,\ldots,\, c_k) &\text{if} \ c_k \in B
                    \end{cases} 
                    && \text{and} &&
                    b_k = \begin{cases}
                        c_k \ &\text{if} \ c_k \in B \\
                        f_k(c_1,\ldots,\, c_k) &\text{if} \ c_k \in A
                    \end{cases}
              \end{align*}
              for positive integers $k \leq n$.
              These terms, based on $f_1,\ldots,\,f_n$, then satisfy $$a_i <_A a_j \iff b_i <_B b_j$$ for all $i,\, j \leq n$, where $i,\, j \in \mathbb{Z}^+$.
    \end{enumerate}
    If no such sequence of functions exists, we say that there exists a \textit{winning strategy of spoiler}.
\end{definition}

The proper definition of a winning strategy lets us define the following type of equivalence:
\begin{definition}[$EF_n$-equivalence]\cite[Definition 6.8]{Ros82}
    We say that a linearly ordered set $A$ is $EF_n$-equivalent to a linearly ordered set $B$,
    if there exists a winning strategy of duplicator in $EF_n(A,\, B)$.

    The orderings $A$ and $B$ are called $EF$-equivalent if duplicator has a winning strategy in $EF_n(A,\, B)$ for all $n \in \mathbb{N}$.
\end{definition}

This is indeed a proper type of equivalence, since by the Gale-Stewart Theorem from game theory all Ehrenfeucht-Fra\"isse games are determined.\cite[\S 6]{Wil24}
This means that one, and only one, of the players will always have a winning strategy.

We saw in Example \ref{game-example-2} that $\mathbb{R}$ and $\mathbb{Q}$ are $EF$-equivalent.
We were able to find a winning strategy for duplicator because both ordered sets were dense. 
As such we could always find a point between any other two points in the rational numbers that could match the order of the possibly irrational points in $\mathbb{R}$.
The sets $\mathbb{R}$ and $\mathbb{Q}$ are of course different, but they still \textit{satisfy the same property} of densely linear orders.

This notion of what structures satisfy which properties is at the core of model theory.
And its no coincidence that Ehrenfeucht-Fra\"isse games seem give rise so naturally to the field. 
We do indeed have a theorem relating them to model theory proper.

\begin{theorem}\cite[Theorem 2.4.6]{Mar02}\label{elementary-eq-th}
    Let $\mathcal{M}$ and $\mathcal{N}$ be two $\mathcal{L}$-structures, where $\mathcal{L}$ is a finite language without any function symbols.
    Then duplicator has a winning strategy in $EF_n(\mathcal{M},\, \mathcal{N})$ for all $n \in \mathbb{N}$ if and only if $\mathcal{M}$ and $\mathcal{N}$ satisfy exactly the same theories.
\end{theorem}
 
We will not prove Theorem \ref{elementary-eq-th} here, but rather include it as an appetizer;
a means show the usefulness of model theory applied to problems we may already be interested in.
The reader interested in the proof of the theorem may read it in the sub-subsection titled ``Ehrenfeucht-Fra\"isse Games'' in \cite[\S 2.4]{Mar02}.
The rest of this chapter should provide an adequate background for understanding it.
 
\section{Syntax of Formal Languages}
The rest of this chapter follows mostly from \cite[\S\S 1.3, 1.4, 2.1]{Cha90}, where the overall structure is preserved, 
although we reformulate and expand on the definitions, theorems and proofs to better fit our context.
Especially some of the earlier definitions are also lifted from \cite{Mar02}.

We utilize set theoretic notation in the definition of languages, however we do not consider the set inclusion symbol $\in$ to be to be part of first-order logic.
In general we are working within \textbf{ZFC} in this chapter.

\begin{definition}
    A \textit{formal language} $\mathcal{L}$ in first order logic is associated with the following sets:
    \begin{enumerate}
        \item A set $\mathcal{F}$ of function symbols $f$ with $n_f$ arguments each, 
        where $n_f \in \mathbb{Z}^+$ is a positive integer;
        \item a set $\mathcal{R}$ of $n_R$-ary relation symbols $R$, 
        where $n_R \in \mathbb{Z}^+$ is a positive integer,
        \item a set $\mathcal{C}$ of constant symbols. \cite[Definition 1.1.1]{Mar02}
    \end{enumerate}
    The set-theoretic structure of $\mathcal{L}$ is $\mathcal{L} = \mathcal{F} \cup \mathcal{R} \cup \mathcal{C}$.
    If $\left\lvert \mathcal{L}\right\rvert$ is the cardinality of the set $\mathcal{L}$ we say that the \textit{power} of the language $\mathcal{L}$ is
    $$\left\lVert \mathcal{L}\right\rVert = \left\lvert\mathcal{L}\right\rvert \cup \omega.$$
    We say that $\mathcal{L}$ is either countable or uncountable depending on whether $\left\lVert\mathcal{L}\right\rVert$ is countable or uncountable. \cite[\S1.3]{Cha90}
\end{definition}

The language of pure sets is the empty language $\mathcal{L}_{Set} = \varnothing$.
In order to make meaningful statements regarding sets however, we need the set inclusion symbol $\in$, which we view as a relation.
Therefore the language of set theory is $\mathcal{L}_{\textbf{ZFC}} = \left\{\in\right\}$. \cite[p.8]{Mar02}\cite[p.80]{Jec78}

Since languages are given by the single set of the symbols they contain, we have that normal set operations are applicable.
If $\mathcal{L}$ and $\mathcal{L}'$ are two languages, such that $\mathcal{L} \subset \mathcal{L}'$, 
we say that $\mathcal{L}'$ is the \textit{expansion} of $\mathcal{L}$ and that $\mathcal{L}$ is the \textit{reduction} of $\mathcal{L}'$.
In the case that $\mathcal{L}'$ is of the form $\mathcal{L}'= \mathcal{L} \cup X$, where $X$ is a set containing only constant symbols, 
we say that $\mathcal{L}'$ is the \textit{simple expansion} of $\mathcal{L}$. \cite[p.19]{Cha90}

In order to express statements in a language we also define \textit{terms}.
These are are expressions created from chaining together function symbols with variables and constants.

\begin{definition}\cite[Definition 1.1.4]{Mar02}
    We say that $T$ is the set of $\mathcal{L}$-terms, if $T$ is the smallest set such that
    \begin{enumerate}[label=(\roman*)]
        \item $c \in T$ for each constant $c \in \mathcal{C}$
        \item $v_i \in T$ for variable symbols $v_i$, where $i = 1,\, 2,\ldots$,
        \item $f(t_1,\ldots,\, t_n) \in T$ for $f \in \mathcal{F}$ and terms $t_1,\ldots,\, t_n \in T$.
    \end{enumerate}
\end{definition}

\begin{example}
    Consider the language of (unitary) rings $\mathcal{L}_r = \left\{+,\, -,\, \cdot,\, 0,\, 1\right\}$.
    The symbols $+,\, -,\, \cdot$ are all binary functions, and $0$ and $1$ are constants.
    Since a language does not possess any external structure itself, this is also the language of fields.

    For variables $v_1$ and $v_2$ we can define the term
    $$\cdot \left(+ \left(v_1.\, 1\right),\, +\left(v_2,\, +\left(1,\, 1\right)\right)\right)$$
    in $\mathcal{L}_r$.
    In more familiar notation this would be
    $$\left(v_1 + 1\right) \cdot \left(v_2 + 1 + 1\right).$$
    Note that this term has can have a different meaning depending on which algebraic structure we evaluate it in.
    In the finite field $\mathbb{F}_2$ for example, we have that $1 + 1 = 0$.
\end{example}

We define formulas in a language $\mathcal{L}$ analogously to how we did in Chapter \ref{preliminaries}.
Note that our definition of a formula in $\mathcal{L}_{\textbf{ZFC}}$ coincides with how we defined it before.

\begin{definition}[Formula in a Language]\cite[Definition 1.1.5]{Mar02}\label{formula-def}
    An \textit{atomic formula} in a language $\mathcal{L}$ is either
    \begin{enumerate}
        \item $t_1 = t_2$ for terms $t_1,\, t_2 \in T$, or   
        \item $R(t_1,\ldots,\, t_{n_R})$ for $R \in \mathcal{R}$ and terms $t_1,\ldots,\, t_{n_R} \in T$.
    \end{enumerate}
    The set of $\mathcal{L}$-formulas is then the smallest set such that
    \begin{enumerate}[label=(\roman*)]
        \item for all $\phi \in \mathcal{W}$, the negation $\lnot \phi$ is also in $\mathcal{W}$,
        \item for all $\phi,\, \psi \in \mathcal{W}$, the formulas $\phi \wedge \psi$ and $\phi \vee \psi$ are also in $\mathcal{W}$,
        \item for all $\phi \in \mathcal{W}$, the formulas $\forall v_i \, \phi$ and $\exists v_i \, \phi$ are also in $\mathcal{W}$.
    \end{enumerate}
    with respect to the logical connectives 
    $$\lnot \text{ (not), } \wedge \text{(and), } \vee \text{(or), } \rightarrow \text{(implies) and } \leftrightarrow \text{(if and only if)}$$
    and quantifiers $$\forall \text{ (for all) and } \exists \text{ (exists)}.$$
    
    Recall that variables occurring inside of a quantifier are called \textit{bound} and that variables which are not bound are called \textit{free}.
    A formula with no free variables is called a \textit{sentence}.
\end{definition}

Note that some of the logical connectives can be considered shorthand of others.
For formulas $\phi$ and $\psi$ we say that $\phi \vee \psi$ is defined as $\lnot \left(\lnot \phi \wedge \lnot \psi\right)$.
We can then express $\phi \rightarrow \psi$ as $\lnot \phi \vee \psi$ and $\phi \leftrightarrow \psi$ as $\left(\phi \rightarrow \psi\right) \wedge \left(\psi \rightarrow \phi\right)$.
Lastly, for a variable $v$, the formula $\forall v\,  \phi(v)$ is considered an abbreviation of $\lnot \left(\exists v\, \lnot \phi\right)$\footnote{
    Alternatively, assuming that $\forall$ is a quantifier, we could also define $\exists v\, \phi(v)$ as $\lnot \left(\forall v\right)\, \lnot \phi(v)$. \cite[p.23]{Cha90}
}. \cite[Remark 1.1.7]{Mar02}

This is a more technical definition of formulas compared to how we defined them in the \hyperref[preliminaries]{Preliminaries}.
It comes from the fact that whenever we want to prove something something is true for all formulas in a language, 
we can use a proof by induction utilizing Definition \ref{formula-def}.
Using the shorthand formulas we only have to consider the cases $\lnot \phi$, $\phi \wedge \psi$ and $\exists v\, \phi(v)$,
for formulas $\phi$ and $\psi$ and some variable $v$.

\begin{proposition}\label{language-cardinality}\cite[Proposition 1.3.4.]{Cha90}
    The set of all formulas of a language $\mathcal{L}$ has cardinality $\left\lVert\mathcal{L}\right\rVert$.
\end{proposition}

\subsection{Logical Axioms}

When working in model theory we consider the difference between \textit{syntax} and \textit{semantics}.
Syntax is everything relating to structure of sentences and formal languages.
This includes what kind of symbols we are working with in a given language and how we can combine them to create valid sentences.

A language is purely \textit{syntactical}, a given sentences in a language has no assigned meaning on its own.
If we are working with a language describing number theory for example, 
we might have a relation symbol $gcd$ which takes in three arguments and returns whether the third argument is the greatest common divisor of the first two.
A formal language only includes the relation symbol itself though, elements for which relations would hold are not part of the language.

Assigning a meaning to a relation symbol such as $gcd$ is \textit{semantics}.
Having a relation be true or false for a some given value is a \textit{semantical} property, this is where the namesake models come in.
In a model the symbols of a language are assigned meaning and we can explore which sentences are or are not true under some given assumptions.\cite[p.3]{Cha90}

There are some sentences which are true in every language however, $x = x$ for example.
We formalize this notion with the following \textit{logical axioms} and \textit{rules of inference}.
This is needed in order to make the syntactical notion of formulas into a \textit{formal system}.
In essence, we define the kind of formulas which have to be true in every model.
This is also why the \textit{axiom} label is justified.

\begin{definition}[Tautology]\cite[pp.8, 24]{Cha90}
    Let $\mathcal{J}$ be a set of simple sentence statements and let $\phi$ be a formula in $\mathcal{J}$.
    Let $\bar{a} = a_1,\ldots a_n$ be a sequence of truth values, meaning each $a_i$ either has the value $t$ for \textit{true} or $f$ for \textit{false}.
    For a such a sentence $\psi$ in $\mathcal{J}$ containing sentence symbols $S_1,\ldots,\, S_n$, 
    an assignment of $\bar{a}$ into $\psi$ substitutes each $S_i$ with $a_i$.

    We say that $\psi$ is a \textit{tautology in sentential logic} if and only if the value of $\psi$ is $t$ for every assignment $\bar{a}$.

    We say that a formula $\phi$ of a formal language $\mathcal{L}$ is \textit{a tautology of} $\mathcal{L}$, 
    if it is possible to obtain $\phi$ by substituting sentence symbols $S_i$ with formulas of $\mathcal{L}$ in a tautology in sentential logic $\psi$. 
\end{definition}

We can think of a formula in $\mathcal{J}$ as a placeholders $S_1,\ldots,\, S_n$ chained together with logical connectives.
Then, when we evaluate it with a sequence of truth values $\bar{a}$, the formula ``terminates'' either in $t$ or $f$.

\begin{example}
    The formula $$\tau = \left(S_1 \implies S_2\right) \vee \left(S_2 \implies S_1\right)$$
    is a tautology in sentential logic.
    No matter which value of $\bar{a} = \left<a_1,\, a_2\right>$ we choose in the set 
    $\left\{\left<t,\, t\right>,\, \left<t,\, f\right>,\, \left<f,\, t\right>,\, \left<f,\, f\right>\right\}$ 
    we always have that $\tau(\bar{a}) = t$.

    Let $\mathcal{L}_{or} = \left\{+,\, -,\, \cdot,\, <,\, 0,\, 1\right\}$ be the language of ordered rings.
    Suppose that $\phi_1$ and $\phi_2$ are the two $\mathcal{L}_{or}$-formulas $v_1 + 1 < v_2$ and $v_2 \cdot v_1 = v_1$ respectively,
    each having (the same) free variables $v_1$ and $v_2$.
    If we substitute the formulas $\phi_1$ and $\phi_2$ into $\tau$, we have that
    \begin{align*}
        \tau_r
        &= \left(\phi_1 \implies \phi_2\right) \vee \left(\phi_2 \implies \phi_1\right) \\
        &= \left(\left(v_1 + 1 < v_2\right) \implies \left(v_2 \cdot v_1 = v_1\right)\right) \\
        &  \qquad \vee \left(\left(v_2 \cdot v_1 = v_1\right) \implies \left(v_1 + 1 < v_2\right)\right)
    \end{align*}
    is a tautology in $\mathcal{L}_{or}$.
    Note that for example $$(v_1 < v_2) \vee (v_1 = v_2) \vee (v_2 < v_1)$$ is not a tautology in $\mathcal{L}_{or}$.
    Intuitively, we can explain this by observing that there are structures of the language which might not interpret the symbol $<$ as a linear order.
\end{example}

\begin{definition}
    We have the three groups of \textit{logical axioms} and two \textit{rules of inference}.
    \begin{enumerate}
        \item \textbf{Sentential Axioms}
        
        Every tautology $\psi$ of $\mathcal{L}$ is a logical axiom. %change wording???
        \item \textbf{Quantifier Axioms}
        \begin{enumerate}
            \item Let $\phi,\, \psi$ be formulas in $\mathcal{L}$ and let $v$ be a variable which is not free in $\phi$.
            Then
            $$\forall v \left((\phi \implies \psi(v)) \implies (\phi \implies \forall v\, \psi(v))\right)$$
            is a logical axiom.
            \item Let $\phi(v)$ be a formula in $\mathcal{L}$ with a free variable $v$.
            Let $\psi$ be a formula in $\mathcal{L}$, 
            such that $\psi$ is the sentence where all free occurrences $v$ in $\psi$ have been substituted by some term $t$.
            This means that no variable of $t$ is bound in $\psi$ at the place it is introduced.
            Then 
            $$\forall v \, \phi(v) \implies \psi$$
            is a logical axiom.
        \end{enumerate}
        \item \textbf{Identity Axioms}
        
        Let $x$ and $y$ be variables and let $t(v_1,\ldots,\, v_n)$ and $\phi(v_1,\ldots,\, v_n)$ be a term and an atomic formula respectively,
        both dependent on free variables $v_1,\ldots,\, v_n$.

        Then 
        \begin{enumerate}
            \item $x = x$,
            \item $\begin{aligned}[t]
                & x = y \implies \\
                & \left(t(v_1,\ldots,\, v_{i-1},\, x,\, v_{i+1},\ldots,\, v_n) = t(v_1,\ldots,v_{i-1},\, y,\, v_{i+1},\ldots,\, v_n)\right),
            \end{aligned}$
            % $x = y \implies$ \newline
            % $\left(t(v_1,\ldots,\, v_{i-1},\, x,\, v_{i+1},\ldots,\, v_n) = t(v_1,\ldots,v_{i-1},\, y,\, v_{i+1},\ldots,\, v_n)\right)$,
            \item $\begin{aligned}[t]
                & x = y \implies \\
                & \left(\phi(v_1,\ldots,\, v_{i-1},\, x,\, v_{i+1},\ldots,\, v_n) \implies \phi(v_1,\ldots,v_{i-1},\, y,\, v_{i+1},\ldots,\, v_n)\right)
            \end{aligned}$
            % $x = y \implies$ \newline
            % $\left(\phi(v_1,\ldots,\, v_{i-1},\, x,\, v_{i+1},\ldots,\, v_n) \implies \phi(v_1,\ldots,v_{i-1},\, y,\, v_{i+1},\ldots,\, v_n)\right)$
        \end{enumerate}
        are logical axioms.
    \end{enumerate}
    The \textit{Rules of Inference} are then
    \begin{enumerate}[resume]
        \item \textbf{Rule of Detachment (Modus Ponens)}
        
        If $\psi$ and $\phi \rightarrow \psi$ hold, then $\psi$ holds.
        \item \textbf{Rule of Generalization}
        
        If $\psi$ holds, then $\forall x\, \psi(x)$ holds.
    \end{enumerate}
\end{definition}

\begin{definition}[Proof]\label{proof-def}\cite[p.25]{Cha90}
    Let $\mathcal{L}$ be a language and let $\Sigma$ be a set of sentences in $\mathcal{L}$.
    We write $\vdash \phi$ to say that a sentence $\phi$ is a theory in $\mathcal{L}$.
    Further, we write $\Sigma \vdash \phi$ to say that the sentence $\phi$ \textit{can be proven from} $\Sigma$ (in conjunction with the logical axioms).
    Another way to say this is to say that $\phi$ \textit{is deductible from} $\Sigma$ or that \textit{there exists a proof of} $\phi$ \textit{from} $\Sigma$.
\end{definition}

A theory can thought of as something that can be proven only from the logical axioms.
While Definition \ref{proof-def} introduces concepts the proof theory, we will in general not be quite that formal when proving sentences in model theory.
However, this type of formality is needed for this next definition and following theorem.

\begin{definition}[Consistency]\cite[p.25]{Cha90}
    A set of sentences $\Sigma$ is \textit{inconsistent} in a language $\mathcal{L}$ if and only if every formula in $\mathcal{L}$ can be proven from $\Sigma$.
    The set $\Sigma$ is called \textit{consistent} if it is not inconsistent.
    We have say that a sentence $\sigma$ is consistent in $\mathcal{L}$ if the singleton set $\left\{\sigma\right\}$ is consistent.

    We say that $\Sigma$ is \textit{maximally consistent} if and only if $\Sigma$ is consistent 
    and no set of sentences $\Sigma'$ which has $\Sigma$ as a proper subset is consistent.
\end{definition}  

This notion of consistency has some fairly intuitive consequences which we provide below and without proof.

\begin{proposition}\label{consistency-prop}\cite[Proposition 1.3.10.]{Cha90}
    Let $\Sigma$ be a set of sentences in a language $\mathcal{L}$. Then
    \begin{enumerate}
        \item the set $\Sigma$ is consistent if and only if every finite subset of $\Sigma$ is consistent;
        \item the set $\Sigma \cup \left\{\sigma\right\}$ is inconsistent for a sentence $\sigma$ if and only if $\Sigma \vdash \lnot \sigma$;
        \item if $\Sigma$ is maximally consistent and $\sigma,\, \tau$ are arbitrary sentences in $\mathcal{L}$, we have that
        \begin{enumerate}[label=(\roman*)]
            \item $\Sigma \vdash \sigma$ if and only if $\sigma \in \Sigma$,
            \item $\sigma \not\in \Sigma$ if and only if $\lnot \sigma \in \Sigma$,
            \item $\sigma \wedge \tau \in \Sigma$ if and only if $\sigma \in \Sigma$ and $\tau \in \Sigma$;
        \end{enumerate}
        \item a formula $\tau$ is deductible from $\Sigma \cup \left\{\sigma\right\}$ for a sentence $\sigma$ if and only if $\Sigma \vdash \sigma \rightarrow \tau$.
    \end{enumerate}

    The last point is also known as the ``Deduction Theorem''.
\end{proposition}

With this proposition in mind we continue on to the final result relating only to formal languages.
After this we move on to actually using these language to construct structures and models.

\begin{theorem}[Lindenbaum's Theorem]\cite[Proposition 1.3.11]{Cha90}
    Let $\Sigma$ be a consistent set of sentences in a language $\mathcal{L}$.
    Then $\Sigma$ can be extended to a maximally consistent set of sentences in $\mathcal{L}$.
\end{theorem}

\begin{proof}\cite[Lemma 1.2.9]{Cha90}  
    By Proposition \ref{language-cardinality} we have that any given language has $\left\lVert \mathcal{L}\right\rVert$ formulas.
    We arrange the sentences of $\mathcal{L}$ in some list
    $$\phi_1,\, \phi_2,\ldots,\, \phi_{\alpha},\ldots$$
    where the specific order is irrelevant, but in a way where each $\phi_{\alpha}$ is associated with an ordinal $\alpha$.
    Based on our existing consistent set of sentences $\Sigma$ we now construct an increasing chain
    $$\Sigma = \Sigma_0 \subset \Sigma_1 \subset \Sigma_2 \subset \cdots \subset \Sigma_{\alpha} \subset \cdots$$
    using this sequence of sentences.
    
    We define $\Sigma_1$ as $\Sigma_0 \cup \phi_0$ if the set $\Sigma_0 \cup \phi_0$ is consistent and choose $\Sigma_1 = \Sigma_0$ otherwise.
    In general, at any given step $\alpha$, we let $\Sigma_{\alpha + 1} = \Sigma_{\alpha} \cup \left\{\phi_{\alpha}\right\}$
    if and only if $\Sigma_{\alpha} \cup \left\{\phi_{\alpha}\right\}$ is consistent.
    If $\Sigma_{\alpha} \cup \left\{\phi_{\alpha}\right\}$ is inconsistent we let $\Sigma_{\alpha + 1} = \Sigma_{\alpha}$.
    Finally, we let $\Gamma$ be the union of all sets $\Sigma_{\  alpha}$.

    The claim is now that $\Gamma$ is consistent and indeed maximally consistent.

    We first assume that $\Gamma$ is inconsistent in order to contrive a contradiction.
    Then, by Proposition \ref{consistency-prop}, there must exist a deduction $\Gamma \vdash \left(\sigma \wedge \lnot\sigma\right)$ for some sentence $\sigma$ in $\mathcal{L}$.
    Assume that $\theta_0,\, \theta_1, \ldots,\, \theta_q$ are the sentences in $\Gamma$ used for this deduction.
    There then exists some ordinal $\alpha$ such that $\theta_0,\, \theta_1, \ldots,\, \theta_q$ all belong to $\Sigma_{\alpha}$.
    The set of sentences $\Sigma_{\alpha}$ is consistent by construction however and we arrive at a contradiction.
    Hence $\Gamma$ must be consistent.

    Assume now that $\Gamma$ is not maximally consistent.
    Then $\Gamma$ is the proper subset of some other consistent set of sentences $\Delta$.
    Let $\phi_{\beta}$ be some sentence in $\Delta$.
    Since both $\Delta$ and $\Gamma$ are consistent and $\Gamma \subset \Delta$, 
    we must have that $\Sigma_{\beta} \cup \left\{\phi_{\beta}\right\}$ also is consistent.
    But if that is the case, we would have that $\Sigma_{\beta + 1} = \Sigma_{\beta} \cup \left\{\phi_{\beta}\right\}$ and therefore $\phi_{\beta} \in \Gamma$.
    As such $\Gamma$ must be maximally consistent.
\end{proof}

\section{Structes, Theories and Models}
\begin{definition}
    A $\mathcal{L}$-\textit{structure} $\mathcal{M}$ is given by the following:
    \begin{enumerate}
        \item A nonempty set $M$,
        \item a function $f^{\mathcal{M}}: M^{n_f} \to M$ for each $f \in \mathcal{F}$,
        \item a set $R^\mathcal{M} \subseteq M^{n_R}$ for each $R \in \mathcal{R}$,
        \item an element $c^\mathcal{M} \in M$ for each $c \in \mathcal{C}$.
    \end{enumerate}
    The set $M$ is referred to as the \textit{universe}, \textit{domain} or \textit{underlying set} of $\mathcal{M}$ 
    and $f^{\mathcal{M}}$, $R^{\mathcal{M}}$ and $c^{\mathcal{M}}$ are called the \textit{interpretations} of $\mathcal{M}$. 
    The \textit{cardinality of} $\mathcal{M}$ is the cardinality of its underlying set $\left\lvert M\right\rvert$. \cite[Definition 1.1.2]{Mar02}

    We sometimes also identify a structure $\mathcal{M}$ by writing $\left(M,\, f^{\mathcal{M}},\, R^{\mathcal{M}},\, c^{\mathcal{M}}\right)$ \cite{Mar02} or $\left(M,\, \mathcal{I}\right)$, 
    where $\mathcal{I}$ is the function mapping symbols of $\mathcal{L}$ to their respective interpretations in $M$. \cite[p.20]{Cha90}
\end{definition}

\begin{definition}\label{structure-embedding-def}\cite[Definition 1.1.3]{Mar02}
    Let $\mathcal{M}$ and $\mathcal{N}$ be two $\mathcal{L}$-structures, having the underlying sets $M$ and $N$ respectively.
    We call a function $\mu: M \to N$ an $\mathcal{L}$-embedding if it is injective and preserves the interpretation of all symbols of $\mathcal{L}$.

    More precisely this means that $\mu$ satisfies
    \begin{enumerate}[label=(\roman*)]
        \item $\mu\left(f^\mathcal{M}(a_1,\ldots,\, a_{n_f})\right) = f^\mathcal{N}(a_1,\ldots,\, a_{n_f})$ 
        for all $f \in \mathcal{F}$ and all sequences $a_1,\ldots,\, a_{n_f}$,
        \item $\left<a_1,\ldots,\, a_{n_R}\right> \in R^\mathcal{M}$ if and only if $\left<\mu(a_1),\ldots,\, \mu(a_{n_R})\right> \in R^\mathcal{N}$ 
        for all $f \in \mathcal{F}$ and $a_1,\ldots,\, a_n$,
        \item $\mu(c^\mathcal{M}) = c^\mathcal{n}$ for all $c \in C$.
    \end{enumerate}
    In the case that $N \subseteq M$, 
    we say that $\mathcal{N}$ is a \textit{substructure} of $\mathcal{M}$ and that $\mathcal{M}$ is an \textit{extension} of $\mathcal{N}$.
\end{definition}

\begin{example}\cite[p.8]{Mar02}
    Let $\mathcal{L}_G = \left\{\cdot,\, e\right\}$ be the language of groups, 
    $\cdot$ is a binary function symbol and $e$ is the constant symbol which we usually associate with the identity element.

    Then $\mathcal{N} = \left(\mathbb{N},\, +,\, 0\right)$ is a $\mathcal{L}_G$-structure, however it is not actually a group.
\end{example}

As discussed earlier, structures are where we explore \textit{semantics}.
To effectively explore semantical ideas in different structures however, 
we first need to actually define what we consider truth in a structure to actually be.

Say we have a term $t$ with (free) variables $v_1,\ldots,\, v_n$,
and we want to know what truth value $t$ takes in some structure when we evaluate it at $\bar{a} = a_1,\ldots,\, a_n$.
One might think that this is function evaluation in the same sense which we usually use it, and they would be mostly correct.
However, since we will use Definition \ref{formula-def} of formulas in defining what truth means for a structure,
we have to be similarly careful when defining term valuation.

\begin{definition}\cite[1.3.13]{Cha90}
    Let $t$ be a term in a language $\mathcal{L}$ dependent on variables $v_1,\ldots,\, v_n$.
    If $\mathcal{M} = \left(M,\, f^{\mathcal{M}},\, R^{\mathcal{M}},\, c^{\mathcal{M}}\right)$ is a $\mathcal{L}$-structure,
    we define the \textit{value of the term} $t(v_1,\ldots,\, v_n)$ \textit{at} $\bar{a} = \left<a_1,\ldots,\, a_n\right> \in M^n$ the following way:
    \begin{enumerate}
        \item If $t$ is $v_i$, then $t(\bar{a}) = a_i$,
        \item if $t$ is the constant symbol $c$ in $\mathcal{L}$, 
        then $t(\bar{a})$ is given by the interpretation $c^{\mathcal{M}}$,
        \item if $t$ is the function $f(t_1,\ldots,\, t_n)$ in $\mathcal{L}$,
        then $t(\bar{a})$ is given by the interpretation 
        $f^{\mathcal{M}}(t_1(\bar{a}),\ldots,\, t_n(\bar{a}))$.
    \end{enumerate}
\end{definition}

We can then define what it means for a sentence to be true in a $\mathcal{L}$-structure:
\begin{definition}\cite[Definition 1.1.6]{Mar02}
    Let $\mathcal{M}$ be an $\mathcal{L}$-structure and let $\phi$ be a formula in $\mathcal{L}$ with free variables $\bar{v} = \left<v_1,\ldots,\, v_n\right>$.
    We inductively define $\mathcal{M} \models \phi(\bar{a})$ and for $\bar{a} = \left<a_1,\ldots,\, a_n\right> \in M^n$.

    \begin{enumerate}
        \item If $\phi$ is $t_1 = t_2$,
        then $\mathcal{M} \models \phi(\bar{a})$ if and only if $t_1(\bar{a}) = t_2(\bar{a})$, 
        \item If $\phi$ is $R\left(t_1,\ldots,\, t_{n_R}\right)$,
        then $\mathcal{M} \models \phi(\bar{a})$ if and only if $\left<t_1(\bar{a}),\ldots,\, t_{n_R}(\bar{a})\right> \in R^{\mathcal{M}}$,
        \item If $\phi$ is $\lnot \psi$, 
        then $\mathcal{M} \models \phi(\bar{a})$ if and only if $\mathcal{M} \not\models \psi(\bar{a})$,
        \item If $\phi$ is $\psi \wedge \rho$, 
        then $\mathcal{M} \models \phi(\bar{a})$ if and only if $\mathcal{M} \models \psi(\bar{a})$ and $\mathcal{M} \models \rho(\bar{a})$,
        \item If $\phi$ is $\exists v_i\, \psi(\bar{v},\, v_i)$,
        then $\mathcal{M} \models \phi(\bar{a})$ if and only if there exists some element $b \in M$ such that $\mathcal{M} \models \psi(\bar{a},\, b)$
    \end{enumerate}

    We say that $\mathcal{M}$ \textit{satisfies} $\phi(\bar{a})$, whenever $\mathcal{M} \models \phi(\bar{a})$.
\end{definition}

\section{The LÃ¶wenheim-Skolem Theorem}

\begin{lemma}\cite[Lemma 2.1.1]{Cha90}
    Let $T$ be a consistent set of sentences of $\mathcal{L}$.  
    Let $C$ be a set of new constant symbols of power $\left\lvert C \right\rvert = \left\lVert \mathcal{L} \right\rVert$
     and let $\bar{\mathcal{L}} = \mathcal{L} \cup C$ be the simple expansion of $\mathcal{L}$ formed by adding $C$.
    
    Then $T$ can be expanded to a consistent set of sentences $\bar{T}$ in $\bar{\mathcal{L}}$, which has $C$ as a set of witnesses in $\bar{\mathcal{L}}$.
\end{lemma}

\begin{lemma}\cite[Lemma 2.1.2]{Cha90}
    Let $T$ be a set of sentences and let $C$ be a set of witnesses of $T$ in $\mathcal{L}$.
    Then $T$ has a model $\mathfrak{U}$, such that every element of $\mathfrak{U}$ is an interpretation of a constant $c \in C$.
\end{lemma} 

\begin{theorem}[Extended Completeness Theorem]\cite[Theorem 1.3.21]{Cha90}
    Let $\Sigma$ be a set of sentences in $\mathcal{L}$.
    Then $\Sigma$ is consistent if and only if $\Sigma$ has a model.
\end{theorem}

\begin{theorem}[Downward LÃ¶wenheim-Skolem Theorem]\label{down-lowenheim-skolem}\cite[Corollary 2.1.4]{Cha90}
    Every consistent theory $T$ in $\mathcal{L}$ has a model of power at most $\left\lVert \mathcal{L} \right\rVert$.
\end{theorem}

\begin{theorem}[Compactness Theorem]\cite[Theorem 1.3.22]{Cha90}
    A set of sentences $\Sigma$ has a model if and only if every finite subset of $\Sigma$ has a model.
\end{theorem}

\begin{theorem}[Upward LÃ¶wenheim-Skolem Theorem]\label{up-lowenheim-skolem}\cite[Corollary 2.1.6]{Cha90}
    If $T$ has infinite models, then it has infinite models of any given power $\alpha \geq \left\lVert \mathcal{L} \right\rVert$.
\end{theorem}

\end{document}