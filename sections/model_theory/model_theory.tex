\documentclass[../../main.tex]{subfiles}
\begin{document}
The aim of this chapter is to give an introduction to the basic tools of model theory with which we will prove the \hyperref[up-lowenheim-skolem]{LÃ¶wenheim-Skolem Theorem}.
This theorem, divided into two parts, is dependent on the \hyperref[choice-axiom]{Axiom of Choice}, 
hence we will later use it to show that \textbf{AC} implies the existence of a group structure on all non-empty sets.

We were already concerned with axiomatizations in the previous chapters, however we will formalize these notions some more here.
The set theory axioms outlined in Chapter \ref{preliminaries} still hold true, 
but we will discover more about what is and is not true in for example group theory or other algebraic structures.
We start the treatment of model theory with the motivating example of ``Ehrenfeucht-Fra\"isse games'', 
exemplifying how the field relates to the linear orderings from Chapter \ref{orderings}.
The impatient or familiar reader however may skip this section without missing any necessary theory.

\section{Ehrenfeucht-Fra\"isse Games}
Let us suppose we are given two linear orderings, based on which we define a two player game.
Player I is called \textit{spoiler} and starts by picking a point on one of the two orderings.
If they pick an element of $A$ we call this $a_1$ and if they pick an element of $B$ we call it $b_1$.
After the spoiler has picked their point, player II will pick a point on the other linear ordering. 
We call player II \textit{duplicator}.\footnote{The names ``spoiler'' and ``duplicator'' were coined by Joel Spencer.\cite[\S 6]{Wil24}
The literature \cite{Ros82} this section of the text is mainly based on uses ``Player I'' and ``Player II'' instead.}
Say spoiler picked $a_1$ in $A$, duplicator then has to pick some element $b_1$ of $B$.

The spoiler and duplicator go back and forth picking points on the linear orderings for a predetermined amount of turns $n$.
Spoiler always gets to choose the ordering they pick a point on and duplicator has to pick something on the other ordering.
The second player, duplicator, wins if the elements $a_1,\ldots,\, a_n$ are in the same order with respect to $A$ as the elements $b_1,\ldots,\, b_n$ are with respect to $B$.
Spoiler wins if duplicator loses, if the elements are not in the same order. 
This is how a single play of an \textit{Ehrenfeucht-Fra\"isse game}, also called a \textit{Back-and-forth game}, in $n$ turns is played out \cite[\S 6.1]{Ros82}.

\begin{example}\label{game-example-1}
    We will go through the play of a game with $3$ steps. 
    Let $A = \mathbb{Q}$ and $B=\mathbb{Z}$ under the usual order be the two linear orderings that are played on.
    
    Spoiler starts and picks the point $a_1 = 0$ in $\mathbb{Q}$. Duplicator on their turn also picks the point $b_0 = 0$ but in $\mathbb{Z}$.
    On the next turn spoiler picks $a_2 = 1$ in $\mathbb{Z}$, duplicator again matches this and picks $b_2 = 1$ in $\mathbb{Q}$.
    Now however spoiler can and does pick $b_3$ in $\mathbb{Q}$ to be $\frac{1}{2}$. 
    This is not possible for duplicator to match since they are now confined to picking a point $a_3$ in $\mathbb{Z}$.
    Hence no matter what point duplicator picks to be $a_3$, they will lose.
\end{example}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[scale=2]
        % draw nodes for game stages 
        \draw[densely dotted] (0,   0) -- (0,   0.2) node[draw, solid, above, align=center] {I,  $a_1$};
        \draw[densely dotted] (1,   0) -- (1,   0.2) node[draw, solid, above, align=center] {I,  $a_2$};
        \draw[densely dotted] (2,   0) -- (2,   0.2) node[draw, solid, above, align=center] {II, $a_3$};
        \draw (2,   0.2) node[draw, cross out, above, align=center] {II, $a_3$};
        \draw[densely dotted] (0,  -2) -- (0,  -1.7) node[draw, solid, above, align=center] {II, $b_1$};
        \draw[densely dotted] (1,  -2) -- (1,  -1.7) node[draw, solid, above, align=center] {II, $b_2$};
        \draw[densely dotted] (0.5,-2) -- (0.5,-1.2) node[draw, solid, above, align=center] {I,  $b_3$};

        % draw both coordinate axes
        \foreach \y/\ytext in {0/A = \mathbb{Z}, -2/B = \mathbb{Q}} {
            \draw[thick, <->] (-1.5, 0 + \y) node[draw, left = 20] {$\ytext$} -- (2.5, 0 + \y);
            \draw[thick] (0,-0.1 + \y) -- (0, 0.1 + \y);
            \foreach \x in {-1, 0,...,2} {
                \draw (\x,-0.05 + \y) -- (\x, 0.05 + \y) node[below = 10] {$\x$};
            }
        }

        % draw extra ticks for Q
        \foreach \x/\xtext in {-0.5/-\frac{1}{2}, 0.5/\frac{1}{2}, 1.5/\frac{3}{2}} {  
            \draw (\x,-0.05 - 2) -- (\x, 0.05 - 2) node[below = 10] {$\xtext$};
        }
    \end{tikzpicture}
    \caption{Example \ref{game-example-1} illustrated.
    Points \textit{spoiler} picked are prefixed by ``I'', points \textit{duplicator} picked are prefixed by ``II''.
    It can be seen that duplicator is not able to pick a suitable element for $b_3$ in $\mathbb{Z}$ such that $a_1$, $a_2$ and $a_3$ have the same order as $b_1$, $b_2$ and $b_3$.}
\end{figure}

It should be clear that in order for spoiler to win, they need to exploit the differences of the linear orders in play.
In the example above spoiler can alway pick their first two elements to be $a_1$ and $a_2$ in $\mathbb{Z}$ in a way where $a_2$ is the immediate successor of $a_1$.
Then, because $\mathbb{Q}$ is dense, no matter which elements duplicator picks to be $b_1$ and $b_2$, spoiler can pick $b_3$ such that $b_1 < b_3 < b_2$.
As $a_2$ is the immediate successor of $a_1$, there exists no element in $\mathbb{Z}$ satisfying  $a_1 < a_3 < a_2$.

This is called a \textit{winning strategy} for spoiler.
A winning strategy for duplicator would be the converse, where duplicator can react according to every possible move by spoiler and still win.
For duplicator to have a winning strategy, the linear orderings should be \textit{similar} in some sort of way, 
in fact the existence of a winning strategy by duplicator is a type of equivalence in itself.
Such a winning strategy shown in the example below, where we play a game with two dense orderings.

\begin{example}\label{game-example-2}
    We play an Ehrenfeucht-Fra\"isse game in $n$ rounds.

    Let $A = \mathbb{R}$ and $B=\mathbb{Q}$ under the usual order.
    We can define a winning strategy for duplicator inductively.
    Duplicator then picks a point according to one of the following cases on an arbitrary turn $i$:
    \begin{enumerate}
        \item It is the first turn and spoiler picks $a_1 \in A$.
        
        Duplicator then picks $b_1 = 0$.
        \item Spoiler picks $a_i \in A$ such that $a_j < a_i < a_k$ holds for some $a_j,\, a_k \in A$.
        
        It can be assumed without loss of generality that $a_j$ and $a_k$ are the respectively largest and smallest points for which this property holds.
        Then there exist corresponding $b_j,\, b_k \in B$ with $b_j < b_k$. Hence duplicator can choose $$b_i = \frac{b_k - b_j}{2}.$$
        \item Spoiler picks $a_i \in A$ such that $a_i$ is either larger or smaller than all $a_k$ for $k < i$.
        
        Duplicator can pick 
        \begin{align*}
            b_i = b_s - 1 && \text{or} && b_i = b_l + 1
        \end{align*}
        in $B$ where $b_s$ and $b_l$ are the smallest and largest elements of $\left\{b_k \,\vert\, k < n\right\}$ respectively.
    \end{enumerate}    
    Since $\mathbb{Q}$ is a proper subset of $\mathbb{R}$ the same strategy works if spoiler chooses an element $b_i$ in $B = \mathbb{Q}$.
    The strategy for the second turn follows immediately from the third case. 
\end{example}

With this example in mind we now formally define the play of an Ehrenfeucht-Fra\"isse game and what it means for duplicator to have a winning strategy.

\begin{definition}[Ehrenfeucht-Fra\"isse Game]\cite[Definition 6.2]{Ros82}
    Let $A$ and $B$ be linear orderings and let $n \in \mathbb{Z}^+$ be a fixed positive integer.
    Then a \textit{play of an Ehrenfeucht-Fra\"isse game} $EF_n(A,\, B)$ is defined as an ordered sequence with $2n$ elements.
    For each positive integer $k \leq n$ player I, \textit{spoiler}, chooses an element in either $A$ or $B$.
    Player II, \textit{duplicator}, then chooses an element of the ordering spoiler did not pick.
    We denote an element at the $k$th turn as $a_k$ if it was picked from $A$ and $b_k$ if it was picked from $B$.

    We say that duplicator has won a play of the game $EF_n(A,\, B)$ if for all positive integers $i,\, j \leq n$
    $$a_i <_A a_j \iff b_i <_B b_j$$
    with respect to the linear orders $<_A$ and $<_B$ of $A$ and $B$.
    We say that spoiler has won a play of the game if duplicator did not win.

    We say that there exists a \textit{winning strategy of duplicator} if there exists a sequence of functions $f_1,\ldots,\,f_n$,
    which fulfills the following requirements:
    \begin{enumerate}[label=(\roman*)]
        \item The domain of each $f_k$ is the set of all ordered $k$-tuples with elements in $A \cup B$;
        \item For elements $c_1,\ldots,\, c_k \in A \cup B$, representing the first $k$ moves by spoiler, 
        the function $f_k$ satisfies
              \begin{align*}
                    &f_k(c_1,\ldots,\, c_k) \in A \ \text{if} \ c_k \in B \ \text{and}\\
                    &f_k(c_1,\ldots,\, c_k) \in B \ \text{if} \ c_k \in A.
              \end{align*}
        \item For elements $c_1,\ldots,\, c_k \in A \cup B$, the additional sequences of functions $a_k$ and $b_k$ are defined as
              \begin{align*}
                a_k = \begin{cases}
                        c_k \ &\text{if} \ c_k \in A \\
                        f_k(c_1,\ldots,\, c_k) &\text{if} \ c_k \in B
                    \end{cases} 
                    && \text{and} &&
                    b_k = \begin{cases}
                        c_k \ &\text{if} \ c_k \in B \\
                        f_k(c_1,\ldots,\, c_k) &\text{if} \ c_k \in A
                    \end{cases}
              \end{align*}
              for positive integers $k \leq n$.
              These terms, based on $f_1,\ldots,\,f_n$, then satisfy $$a_i <_A a_j \iff b_i <_B b_j$$ for all $i,\, j \leq n$, where $i,\, j \in \mathbb{Z}^+$.
    \end{enumerate}
    If no such sequence of functions exists, we say that there exists a \textit{winning strategy of spoiler}.
\end{definition}

The proper definition of a winning strategy lets us define the following type of equivalence:
\begin{definition}[$EF_n$-equivalence]\cite[Definition 6.8]{Ros82}
    We say that a linearly ordered set $A$ is \emph{$EF_n$-equivalent} to a linearly ordered set $B$,
    if there exists a winning strategy of duplicator in $EF_n(A,\, B)$.

    The orderings $A$ and $B$ are called \emph{$EF$-equivalent} if duplicator has a winning strategy in $EF_n(A,\, B)$ for all $n \in \mathbb{N}$.
\end{definition}

This is indeed a proper type of equivalence, since all Ehrenfeucht-Fra\"isse games are determined.
This means that one, and only one, of the players will always have a winning strategy \cite[\S 6]{Wil24}.

We saw in Example \ref{game-example-2} that $\mathbb{R}$ and $\mathbb{Q}$ are $EF$-equivalent.
We were able to find a winning strategy for duplicator because both ordered sets were dense. 
As such we could always find a point between any other two points in the rational numbers that could match the order of the possibly irrational points in $\mathbb{R}$.
The sets $\mathbb{R}$ and $\mathbb{Q}$ are of course different, but they still \textit{satisfy the same property} of densely linear orders.

This notion of what structures satisfy which properties is at the core of model theory.
And it is no coincidence that Ehrenfeucht-Fra\"isse games seem to arise so naturally in the field. 
We do indeed have a theorem relating them to model theory proper.

\begin{theorem}\label{elementary-eq-th}\cite[Theorem 2.4.6]{Mar02}
    Let $\mathcal{M}$ and $\mathcal{N}$ be two \hyperref[structure-def]{$\mathcal{L}$-structures}, where $\mathcal{L}$ is a finite language without any function symbols.
    Then duplicator has a winning strategy in $EF_n(\mathcal{M},\, \mathcal{N})$ for all $n \in \mathbb{N}$ if and only if $\mathcal{M}$ and $\mathcal{N}$ satisfy exactly the same theories.
\end{theorem}
 
We will not prove Theorem \ref{elementary-eq-th} here, but rather include it as an appetizer;
a means show the usefulness of model theory applied to problems we may already be interested in.
The reader interested in the proof of the theorem may read it in the subsection titled ``Ehrenfeucht-Fra\"isse Games'' in \cite[\S 2.4]{Mar02}.
The rest of this chapter should provide an adequate background for understanding it.
 
\section{Syntax of Formal Languages}
The rest of this chapter follows mostly from \cite[\S\S 1.3, 1.4, 2.1]{Cha90}, where the overall structure is preserved, 
although we reformulate and expand on the definitions, theorems and proofs to better fit our context.
Especially some of the earlier definitions are also lifted from \cite{Mar02}.

We utilize set theoretic notation in the definition of languages, however we do not consider the set inclusion symbol $\in$ to be to be part of first-order logic.
In general we are working within \textbf{ZFC} in this chapter.

\begin{definition}\label{language-def}\cite[Definition 1.1.1]{Mar02}
    A \textit{formal language} $\mathcal{L}$ in first order logic is associated with the following sets:
    \begin{enumerate}
        \item A set $\mathcal{F}$ of function symbols $f$ with $n_f$ arguments each, 
        where $n_f \in \mathbb{Z}^+$ is a positive integer;
        \item a set $\mathcal{R}$ of $n_R$-ary relation symbols $R$, 
        where $n_R \in \mathbb{Z}^+$ is a positive integer,
        \item a set $\mathcal{C}$ of constant symbols.
    \end{enumerate}
    The set-theoretic structure of $\mathcal{L}$ is $\mathcal{L} = \mathcal{F} \cup \mathcal{R} \cup \mathcal{C}$.
    If $\left\lvert \mathcal{L}\right\rvert$ is the cardinality of the set $\mathcal{L}$ we say that the \emph{power} of the language $\mathcal{L}$ is
    $$\left\lVert \mathcal{L}\right\rVert = \left\lvert\mathcal{L}\right\rvert \cup \omega,$$
    where $\omega$ is the cardinality of the natural numbers.
    We say that $\mathcal{L}$ is either \emph{countable} or \emph{uncountable} depending on whether $\left\lVert\mathcal{L}\right\rVert$ is countable or uncountable \cite[\S1.3]{Cha90}.
\end{definition}

The language of pure sets is the empty language $\mathcal{L}_{Set} = \varnothing$.
In order to make meaningful statements regarding sets however, we need the set inclusion symbol $\in$, which we view as a relation.
Therefore the language of set theory is $\mathcal{L}_{\textbf{ZFC}} = \left\{\in\right\}$ \cite[p.8]{Mar02}\cite[p.80]{Jec78}.

Since languages are given by the single set of the symbols they contain, we have that normal set operations are applicable.
If $\mathcal{L}$ and $\mathcal{L}'$ are two languages, such that $\mathcal{L} \subset \mathcal{L}'$, 
we say that $\mathcal{L}'$ is the \textit{expansion} of $\mathcal{L}$ and that $\mathcal{L}$ is the \textit{reduction} of $\mathcal{L}'$.
In the case that $\mathcal{L}'$ is of the form $\mathcal{L}'= \mathcal{L} \cup X$, where $X$ is a set containing only constant symbols, 
we say that $\mathcal{L}'$ is the \textit{simple expansion} of $\mathcal{L}$ \cite[p.19]{Cha90}.

In order to express statements in a language we also define \textit{terms}.
These are are expressions created from chaining together function symbols with variables and constants.

\begin{definition}\label{term-def}\cite[Definition 1.1.4]{Mar02}
    We say that $T$ is the set of \emph{$\mathcal{L}$-terms}, if $T$ is the smallest set such that
    \begin{enumerate}[label=(\roman*)]
        \item $c \in T$ for each constant $c \in \mathcal{C}$
        \item $v_i \in T$ for variable symbols $v_i$, where $i = 1,\, 2,\ldots$,
        \item $f(t_1,\ldots,\, t_n) \in T$ for each $f \in \mathcal{F}$ and terms $t_1,\ldots,\, t_n \in T$.
    \end{enumerate}
\end{definition}

Notice that we did not include relation symbols $R$ of $\mathcal{L}$ in Definition \ref{term-def}.
We can think of terms as stand-in for values in the language.
In contrast, we include relation symbols in Definition \ref{formula-def} of formulas below.
Formulas always carry with them a notion of being either true or false, which is not the case for terms.
This is reflected in the way we think about relations as well: a relation either holds or does not hold for a certain set of values.

\begin{example}
    Consider the language of (unitary) rings $\mathcal{L}_r = \left\{+,\, -,\, \cdot,\, 0,\, 1\right\}$.
    The symbols $+,\, -,\, \cdot$ are all binary functions, and $0$ and $1$ are constants.
    Since a language does not possess any external structure itself, this is also the language of fields.

    For variables $v_1$ and $v_2$ we can define the term
    $$\cdot \left(+ \left(v_1.\, 1\right),\, +\left(v_2,\, +\left(1,\, 1\right)\right)\right)$$
    in $\mathcal{L}_r$.
    In more familiar notation this would be
    $$\left(v_1 + 1\right) \cdot \left(v_2 + 1 + 1\right).$$
    Note that this term can have a different meaning depending on which algebraic structure we evaluate it in.
    In the finite field $\mathbb{F}_2$ for example, we have that $1 + 1 = 0$.
\end{example}

We define formulas in a language $\mathcal{L}$ analogously to how we did in Chapter \ref{preliminaries}.
Note that our definition of a formula in $\mathcal{L}_{\textbf{ZFC}}$ coincides with how we defined it before.

\begin{definition}[Formula in a Language]\cite[Definition 1.1.5]{Mar02}\label{formula-def}
    An \textit{atomic formula} in a language $\mathcal{L}$ is either
    \begin{enumerate}
        \item $t_1 = t_2$ for terms $t_1,\, t_2 \in T$, or   
        \item $R(t_1,\ldots,\, t_{n_R})$ for $R \in \mathcal{R}$ and terms $t_1,\ldots,\, t_{n_R} \in T$.
    \end{enumerate}
    The set of $\mathcal{L}$-formulas is then the smallest set $\mathcal{W}$ such that
    \begin{enumerate}[label=(\roman*)]
        \item for all $\phi \in \mathcal{W}$, the negation $\lnot \phi$ is also in $\mathcal{W}$,
        \item for all $\phi,\, \psi \in \mathcal{W}$, the formulas $\phi \wedge \psi$ and $\phi \vee \psi$ are also in $\mathcal{W}$,
        \item for all $\phi \in \mathcal{W}$, the formulas $\forall v_i \, \phi$ and $\exists v_i \, \phi$ are also in $\mathcal{W}$,
    \end{enumerate}
    with respect to the logical connectives 
    $$\lnot \text{ (not), } \wedge \text{(and), } \vee \text{(or), } \rightarrow \text{(implies)}\quad \text{and}\quad \leftrightarrow \text{(if and only if)}$$
    and quantifiers $$\forall \text{ (for all)}\quad \text{and}\quad \exists \text{ (exists)}.$$
    
    Recall that variables occurring inside of a quantifier are called \textit{bound} and that variables which are not bound are called \textit{free}.
    A formula with no free variables is called a \textit{sentence}.
\end{definition}
An example of a formula $\phi(v)$ with a free variable $v$ would be $\exists w \, (v = w)$.
An simple example of a sentence would be $\forall x \, \exists y \, R(x,\, y)$, where $R$ is a binary relation symbol.

Note that some of the logical connectives can be considered shorthand of others.
For formulas $\phi$ and $\psi$ we say that $\phi \vee \psi$ is defined as $\lnot \left(\lnot \phi \wedge \lnot \psi\right)$.
We can then express $\phi \rightarrow \psi$ as $\lnot \phi \vee \psi$ and $\phi \leftrightarrow \psi$ as $\left(\phi \rightarrow \psi\right) \wedge \left(\psi \rightarrow \phi\right)$.
Lastly, for a variable $v$, the formula $\forall v\,  \phi(v)$ is considered an abbreviation of $\lnot \left(\exists v\, \lnot \phi\right)$\footnote{
    Alternatively, assuming that $\forall$ is a quantifier, we could also define $\exists v\, \phi(v)$ as $\lnot \left(\forall v\right)\, \lnot \phi(v)$ \cite[p.23]{Cha90}.
} \cite[Remark 1.1.7]{Mar02}.

This is a more technical definition of formulas compared to how we defined them in the \hyperref[preliminaries]{Preliminaries}.
It comes from the fact that whenever we want to prove something is true for all formulas in a language, 
we can use a proof by induction utilizing Definition \ref{formula-def}.
Using the shorthand formulas we only have to consider the cases $\lnot \phi$, $\phi \wedge \psi$ and $\exists v\, \phi(v)$,
for formulas $\phi$ and $\psi$ and some variable $v$.

\begin{proposition}\label{language-cardinality}\cite[Proposition 1.3.4.]{Cha90}
    The set of all formulas of a language $\mathcal{L}$ has cardinality $\left\lVert\mathcal{L}\right\rVert$.
\end{proposition}

\subsection{Logical Axioms}

When working in model theory we consider the difference between \textit{syntax} and \textit{semantics}.
Syntax is everything relating to structure of sentences and formal languages.
This includes what kind of symbols we are working with in a given language and how we can combine them to create valid sentences.

A language is purely \textit{syntactical}, a given sentence in a language has no assigned meaning on its own.
If we are working with a language describing number theory for example, 
we might have a relation symbol $gcd$ which takes in three arguments and returns whether the third argument is the greatest common divisor of the first two.
A formal language only includes the relation symbol itself though, elements for which relations would hold are not part of the language.

Assigning a meaning to a relation symbol such as $gcd$ is \textit{semantics}.
Having a relation be true or false for a some given value is a \textit{semantical} property, this is where the namesake models come in.
In a model the symbols of a language are assigned meaning and we can explore which sentences are or are not true under some given assumptions.\cite[p.3]{Cha90}

There are some sentences which are true in every language however, $x = x$ for example.
We formalize this notion with the following \textit{logical axioms} and \textit{rules of inference}.
This is needed in order to make the syntactical notion of formulas into a \textit{formal system}.
In essence, we define the kind of formulas which have to be true in every model.
This is also why the \textit{axiom} label is justified.

\begin{definition}[Tautology]\cite[pp.8, 24]{Cha90}
    Let $\mathcal{J}$ be a set of simple sentence statements and let $\phi$ be a formula in $\mathcal{J}$.
    Let $\overline{a} = a_1,\ldots,\, a_n$ be a sequence of truth values, meaning each $a_i$ either has the value $t$ for \textit{true} or $f$ for \textit{false}.
    For a such a sentence $\psi$ in $\mathcal{J}$ containing sentence symbols $S_1,\ldots,\, S_n$, 
    an assignment of $\overline{a}$ into $\psi$ substitutes each $S_i$ with $a_i$.

    We say that $\psi$ is a \textit{tautology in sentential logic} if and only if the value of $\psi$ is $t$ for every assignment $\overline{a}$.

    We say that a formula $\phi$ of a formal language $\mathcal{L}$ is \textit{a tautology of} $\mathcal{L}$, 
    if it is possible to obtain $\phi$ by substituting sentence symbols $S_i$ with formulas of $\mathcal{L}$ in a tautology in sentential logic $\psi$. 
\end{definition}

We can think of a formula in $\mathcal{J}$ as a placeholders $S_1,\ldots,\, S_n$ chained together with logical connectives.
Then, when we evaluate it with a sequence of truth values $\overline{a}$, the formula ``terminates'' either in $t$ or $f$.

\begin{example}
    The formula $$\tau = \left(S_1 \rightarrow S_2\right) \vee \left(S_2 \rightarrow S_1\right)$$
    is a tautology in sentential logic.
    No matter which value of $\overline{a} = \left<a_1,\, a_2\right>$ we choose in the set 
    $\left\{\left<t,\, t\right>,\, \left<t,\, f\right>,\, \left<f,\, t\right>,\, \left<f,\, f\right>\right\}$ 
    we always have that $\tau(\overline{a}) = t$.

    Let $\mathcal{L}_{or} = \left\{+,\, -,\, \cdot,\, <,\, 0,\, 1\right\}$ be the language of ordered rings.
    Suppose that $\phi_1$ and $\phi_2$ are the two $\mathcal{L}_{or}$-formulas $v_1 + 1 < v_2$ and $v_2 \cdot v_1 = v_1$ respectively,
    each having (the same) free variables $v_1$ and $v_2$.
    If we substitute the formulas $\phi_1$ and $\phi_2$ into $\tau$, we have that
    \begin{align*}
        \tau_r
        &= \left(\phi_1 \rightarrow \phi_2\right) \vee \left(\phi_2 \rightarrow \phi_1\right) \\
        &= \big(\left(v_1 + 1 < v_2\right) \rightarrow \left(v_2 \cdot v_1 = v_1\right)\big) \\
        &  \qquad \vee \big(\left(v_2 \cdot v_1 = v_1\right) \rightarrow \left(v_1 + 1 < v_2\right)\big)
    \end{align*}
    is a tautology in $\mathcal{L}_{or}$.
    Note that for example $$(v_1 < v_2) \vee (v_1 = v_2) \vee (v_2 < v_1)$$ is not a tautology in $\mathcal{L}_{or}$.
    Intuitively, we can explain this by observing that there are structures of the language which might not interpret the symbol $<$ as a linear order.
\end{example}

\begin{definition}\cite[1.3.5-1.3.9.]{Cha90}
    We have three groups of \textit{logical axioms} and two \textit{rules of inference} given below.
    We start with the logical axioms.
    \begin{enumerate}
        \item \textbf{Sentential Axioms}
        
        Every tautology $\psi$ of $\mathcal{L}$ is a logical axiom. %change wording???
        \item\label{quantifier-axioms} \textbf{Quantifier Axioms}
        \begin{enumerate}
            \item Let $\phi,\, \psi$ be formulas in $\mathcal{L}$ and let $v$ be a variable which is not free in $\phi$.
            Then
            $$\forall v \left((\phi \rightarrow \psi(v)) \rightarrow (\phi \rightarrow \forall v\, \psi(v))\right)$$
            is a logical axiom.
            \item Let $\phi(v)$ be a formula in $\mathcal{L}$ with a free variable $v$.
            Let $\psi$ be a formula in $\mathcal{L}$, 
            such that $\psi$ is the sentence where all free occurrences $v$ in $\psi$ have been substituted by some term $t$.
            This means that no variable of $t$ is bound in $\psi$ at the place it is introduced.
            Then 
            $$\forall v \, \phi(v) \rightarrow \psi$$
            is a logical axiom.
        \end{enumerate}
        \item\label{identity-axioms} \textbf{Identity Axioms}
        
        Let $x$ and $y$ be variables and let $t(v_1,\ldots,\, v_n)$ and $\phi(v_1,\ldots,\, v_n)$ be a term and an atomic formula respectively,
        both dependent on free variables $v_1,\ldots,\, v_n$.

        Then 
        \begin{enumerate}
            \item $x = x$,
            \item $\begin{aligned}[t]
                & x = y \rightarrow \\
                & \left(t(v_1,\ldots,\, v_{i-1},\, x,\, v_{i+1},\ldots,\, v_n) = t(v_1,\ldots,v_{i-1},\, y,\, v_{i+1},\ldots,\, v_n)\right),
            \end{aligned}$
            % $x = y \rightarrow$ \newline
            % $\left(t(v_1,\ldots,\, v_{i-1},\, x,\, v_{i+1},\ldots,\, v_n) = t(v_1,\ldots,v_{i-1},\, y,\, v_{i+1},\ldots,\, v_n)\right)$,
            \item $\begin{aligned}[t]
                & x = y \rightarrow \\
                & \left(\phi(v_1,\ldots,\, v_{i-1},\, x,\, v_{i+1},\ldots,\, v_n) \rightarrow \phi(v_1,\ldots,v_{i-1},\, y,\, v_{i+1},\ldots,\, v_n)\right)
            \end{aligned}$
            % $x = y \rightarrow$ \newline
            % $\left(\phi(v_1,\ldots,\, v_{i-1},\, x,\, v_{i+1},\ldots,\, v_n) \rightarrow \phi(v_1,\ldots,v_{i-1},\, y,\, v_{i+1},\ldots,\, v_n)\right)$
        \end{enumerate}
        are logical axioms.
    \end{enumerate}
    The \textit{Rules of Inference} are then
    \begin{enumerate}[resume]
        \item\label{detachment-rule} \textbf{Rule of Detachment (Modus Ponens)}
        
        If $\psi$ and $\phi \rightarrow \psi$ hold, then $\psi$ holds.
        \item\label{generalization-rule} \textbf{Rule of Generalization}
        
        If $\psi$ holds, then $\forall x\, \psi(x)$ holds.
    \end{enumerate}
\end{definition}

\begin{definition}[Proof]\label{proof-def}\cite[p.25]{Cha90}
    Let $\mathcal{L}$ be a language and let $\Sigma$ be a set of sentences in $\mathcal{L}$.
    We write $\vdash \phi$ to say that a sentence $\phi$ is a theory in $\mathcal{L}$.
    Further, we write $\Sigma \vdash \phi$ to say that the sentence $\phi$ \textit{can be proven from} $\Sigma$ (in conjunction with the logical axioms).
    Another way to say this is to say that $\phi$ \textit{is deductible from} $\Sigma$ or that \textit{there exists a proof of} $\phi$ \textit{from} $\Sigma$.
\end{definition}

A theory can thought of as something that can be proven only from the logical axioms.
While Definition \ref{proof-def} introduces concepts from proof theory, we will in general not be quite as thorough when proving sentences in model theory.
However, this type of formality is needed for the next definition and following theorem.

\begin{definition}[Consistency]\cite[p.25]{Cha90}
    A set of sentences $\Sigma$ is \emph{inconsistent} in a language $\mathcal{L}$ if and only if every formula in $\mathcal{L}$ can be proven from $\Sigma$.
    The set $\Sigma$ is called \emph{consistent} if it is not inconsistent.
    We say that a sentence $\sigma$ is \emph{consistent} in $\mathcal{L}$ if the singleton set $\left\{\sigma\right\}$ is consistent.

    We say that $\Sigma$ is \emph{maximally consistent} if and only if $\Sigma$ is consistent 
    and no set of sentences $\Sigma'$ which has $\Sigma$ as a proper subset is consistent.
\end{definition}  

This notion of consistency has some fairly intuitive consequences which we provide below and without proof.

\begin{proposition}\label{consistency-prop}\cite[Proposition 1.3.10.]{Cha90}
    Let $\Sigma$ be a set of sentences in a language $\mathcal{L}$. Then
    \begin{enumerate}
        \item the set $\Sigma$ is consistent if and only if every finite subset of $\Sigma$ is consistent;
        \item the set $\Sigma \cup \left\{\sigma\right\}$ is inconsistent for a sentence $\sigma$ if and only if $\Sigma \vdash \lnot \sigma$;
        \item if $\Sigma$ is maximally consistent and $\sigma,\, \tau$ are arbitrary sentences in $\mathcal{L}$, we have that
        \begin{enumerate}[label=(\roman*)]
            \item $\Sigma \vdash \sigma$ if and only if $\sigma \in \Sigma$,
            \item $\sigma \not\in \Sigma$ if and only if $\lnot \sigma \in \Sigma$,
            \item $\sigma \wedge \tau \in \Sigma$ if and only if $\sigma \in \Sigma$ and $\tau \in \Sigma$;
        \end{enumerate}
        \item a formula $\tau$ is deductible from $\Sigma \cup \left\{\sigma\right\}$ for a sentence $\sigma$ if and only if $\Sigma \vdash \sigma \rightarrow \tau$.
    \end{enumerate}

    The last point is also known as the ``Deduction Theorem''.
\end{proposition}

With this proposition in mind we continue on to the final result relating only to formal languages.
After this we move on to actually using these language to construct structures and models.

\begin{theorem}[Lindenbaum's Theorem]\label{lindenbaums-theorem}\cite[Proposition 1.3.11]{Cha90}
    Let $\Sigma$ be a consistent set of sentences in a language $\mathcal{L}$.
    Then $\Sigma$ can be extended to a maximally consistent set of sentences in $\mathcal{L}$.
\end{theorem}

\begin{proof}\cite[Lemma 1.2.9]{Cha90}  
    By Proposition \ref{language-cardinality} we have that any given language has $\left\lVert \mathcal{L}\right\rVert$ formulas.
    We arrange the sentences of $\mathcal{L}$ in some list
    $$\phi_1,\, \phi_2,\ldots,\, \phi_{\alpha},\ldots$$
    where the specific order is irrelevant, but in a way where each $\phi_{\alpha}$ is associated with an ordinal $\alpha$.
    This is possible since we are working within \textbf{ZFC} and as such every set has a well-order.

    Based on our existing consistent set of sentences $\Sigma$ we now construct an increasing chain
    $$\Sigma = \Sigma_0 \subset \Sigma_1 \subset \Sigma_2 \subset \cdots \subset \Sigma_{\alpha} \subset \cdots$$
    using this sequence of sentences.
    
    We define $\Sigma_1$ as $\Sigma_0 \cup \phi_0$ if the set $\Sigma_0 \cup \phi_0$ is consistent and choose $\Sigma_1 = \Sigma_0$ otherwise.
    In general, at any given step $\alpha$, we let $\Sigma_{\alpha + 1} = \Sigma_{\alpha} \cup \left\{\phi_{\alpha}\right\}$
    if and only if $\Sigma_{\alpha} \cup \left\{\phi_{\alpha}\right\}$ is consistent.
    If $\Sigma_{\alpha} \cup \left\{\phi_{\alpha}\right\}$ is inconsistent we let $\Sigma_{\alpha + 1} = \Sigma_{\alpha}$.
    Finally, we let $\Gamma$ be the union of all sets $\Sigma_{\alpha}$.

    The claim is now that $\Gamma$ is consistent and indeed maximally consistent.

    We first assume that $\Gamma$ is inconsistent in order to contrive a contradiction.
    Then, by Proposition \ref{consistency-prop}, there must exist a deduction $\Gamma \vdash \left(\sigma \wedge \lnot\sigma\right)$ for some sentence $\sigma$ in $\mathcal{L}$.
    Assume that $\theta_0,\, \theta_1, \ldots,\, \theta_q$ are the sentences in $\Gamma$ used for this deduction.
    There then exists some ordinal $\alpha$ such that $\theta_0,\, \theta_1, \ldots,\, \theta_q$ all belong to $\Sigma_{\alpha}$.
    The set of sentences $\Sigma_{\alpha}$ is consistent by construction however and we arrive at a contradiction.
    Hence $\Gamma$ must be consistent.

    Assume now that $\Gamma$ is not maximally consistent.
    Then $\Gamma$ is the proper subset of some other consistent set of sentences $\Delta$.
    Let $\phi_{\beta}$ be some sentence in $\Delta$.
    Since both $\Delta$ and $\Gamma$ are consistent and $\Gamma \subset \Delta$, 
    we must have that $\Sigma_{\beta} \cup \left\{\phi_{\beta}\right\}$ also is consistent.
    But if that is the case, we would have that $\Sigma_{\beta + 1} = \Sigma_{\beta} \cup \left\{\phi_{\beta}\right\}$ and therefore $\phi_{\beta} \in \Gamma$.
    As such $\Gamma$ must be maximally consistent.
\end{proof}

\section{Structures, Theories and Models}
\begin{definition}\label{structure-def}
    A $\mathcal{L}$-\textit{structure} $\mathcal{M}$ is given by the following:
    \begin{enumerate}
        \item a non-empty set $M$,
        \item a function $f^{\mathcal{M}}: M^{n_f} \to M$ for each $f \in \mathcal{F}$,
        \item a set $R^\mathcal{M} \subseteq M^{n_R}$ for each $R \in \mathcal{R}$,
        \item an element $c^\mathcal{M} \in M$ for each $c \in \mathcal{C}$.
    \end{enumerate}
    The set $M$ is referred to as the \textit{universe}, \textit{domain} or \textit{underlying set} of $\mathcal{M}$ 
    and $f^{\mathcal{M}}$, $R^{\mathcal{M}}$ and $c^{\mathcal{M}}$ are called the \textit{interpretations} of $\mathcal{M}$. 
    The \textit{cardinality of} $\mathcal{M}$ is the cardinality of its underlying set $\left\lvert M\right\rvert$ \cite[Definition 1.1.2]{Mar02}.

    We sometimes also identify a structure $\mathcal{M}$ by writing $\left(M,\, f^{\mathcal{M}},\, R^{\mathcal{M}},\, c^{\mathcal{M}}\right)$ \cite{Mar02} or $\left(M,\, \mathcal{I}\right)$, 
    where $\mathcal{I}$ is the function mapping symbols of $\mathcal{L}$ to their respective interpretations in $M$ \cite[p.20]{Cha90}.
\end{definition}

\begin{definition}\label{structure-embedding-def}\cite[Definition 1.1.3]{Mar02}
    Let $\mathcal{M}$ and $\mathcal{N}$ be two $\mathcal{L}$-structures, having the underlying sets $M$ and $N$ respectively.
    We call a function $\mu: M \to N$ an $\mathcal{L}$-embedding if it is injective and preserves the interpretation of all symbols of $\mathcal{L}$.

    More precisely this means that $\mu$ satisfies
    \begin{enumerate}[label=(\roman*)]
        \item $\mu\left(f^\mathcal{M}(a_1,\ldots,\, a_{n_f})\right) = f^\mathcal{N}(a_1,\ldots,\, a_{n_f})$ 
        for all $f \in \mathcal{F}$ and all sequences $a_1,\ldots,\, a_{n_f}$,
        \item $\left<a_1,\ldots,\, a_{n_R}\right> \in R^\mathcal{M}$ if and only if $\left<\mu(a_1),\ldots,\, \mu(a_{n_R})\right> \in R^\mathcal{N}$ 
        for all $f \in \mathcal{F}$ and $a_1,\ldots,\, a_n$,
        \item $\mu(c^\mathcal{M}) = c^\mathcal{n}$ for all $c \in C$.
    \end{enumerate}
    In the case that $N \subseteq M$, 
    we say that $\mathcal{N}$ is a \textit{substructure} of $\mathcal{M}$ and that $\mathcal{M}$ is an \textit{extension} of $\mathcal{N}$.
\end{definition}

\begin{example}\cite[p.8]{Mar02}
    Let $\mathcal{L}_G = \left\{\cdot,\, e\right\}$ be the language of groups, 
    $\cdot$ is a binary function symbol and $e$ is the constant symbol which we usually associate with the identity element.

    Then $\mathcal{N} = \left(\mathbb{N},\, +,\, 0\right)$ is an $\mathcal{L}_G$-structure, however it is not actually a group.
\end{example}

As discussed earlier, structures are where we explore \textit{semantics}.
To effectively explore semantical ideas in different structures however, 
we first need to actually define what we consider truth in a structure to actually be.

Say we have a term $t$ with (free) variables $v_1,\ldots,\, v_n$,
and we want to know what truth value $t$ takes in some structure when we evaluate it at $\overline{a} = a_1,\ldots,\, a_n$.
One might think that this is function evaluation in the same sense which we usually use it, and they would be mostly correct.
However, since we will use Definition \ref{formula-def} of formulas in defining what truth means for a structure,
we have to be similarly careful when defining term valuation.

\begin{definition}\cite[1.3.13]{Cha90}
    Let $t$ be a term in a language $\mathcal{L}$ dependent on variables $v_1,\ldots,\, v_n$.
    If $\mathcal{M} = \left(M,\, f^{\mathcal{M}},\, R^{\mathcal{M}},\, c^{\mathcal{M}}\right)$ is an $\mathcal{L}$-structure,
    we define the \textit{value of the term} $t(v_1,\ldots,\, v_n)$ \textit{at} $\overline{a} = \left<a_1,\ldots,\, a_n\right> \in M^n$ the following way:
    \begin{enumerate}
        \item if $t$ is $v_i$, then $t(\overline{a}) = a_i$,
        \item if $t$ is the constant symbol $c$ in $\mathcal{L}$, 
        then $t(\overline{a})$ is given by the interpretation $c^{\mathcal{M}}$,
        \item if $t$ is the function $f(t_1,\ldots,\, t_n)$ in $\mathcal{L}$,
        then $t(\overline{a})$ is given by the interpretation 
        $f^{\mathcal{M}}(t_1(\overline{a}),\ldots,\, t_n(\overline{a}))$.
    \end{enumerate}
\end{definition}

We can then define what it means for a sentence to be true in an $\mathcal{L}$-structure:
\begin{definition}\label{model-satisfaction-def}\cite[Definition 1.1.6]{Mar02}
    Let $\mathcal{M}$ be an $\mathcal{L}$-structure and let $\phi$ be a formula in $\mathcal{L}$ with free variables $\overline{v} = \left<v_1,\ldots,\, v_n\right>$.
    We inductively define $\mathcal{M} \models \phi(\overline{a})$ and for $\overline{a} = \left<a_1,\ldots,\, a_n\right> \in M^n$.

    \begin{enumerate}
        \item If $\phi$ is $t_1 = t_2$,
        then $\mathcal{M} \models \phi(\overline{a})$ if and only if $t_1(\overline{a}) = t_2(\overline{a})$, 
        \item If $\phi$ is $R\left(t_1,\ldots,\, t_{n_R}\right)$,
        then $\mathcal{M} \models \phi(\overline{a})$ if and only if $\left<t_1(\overline{a}),\ldots,\, t_{n_R}(\overline{a})\right> \in R^{\mathcal{M}}$,
        \item If $\phi$ is $\lnot \psi$, 
        then $\mathcal{M} \models \phi(\overline{a})$ if and only if $\mathcal{M} \not\models \psi(\overline{a})$,
        \item If $\phi$ is $\psi \wedge \rho$, 
        then $\mathcal{M} \models \phi(\overline{a})$ if and only if $\mathcal{M} \models \psi(\overline{a})$ and $\mathcal{M} \models \rho(\overline{a})$,
        \item If $\phi$ is $\exists v_i\, \psi(\overline{v},\, v_i)$,
        then $\mathcal{M} \models \phi(\overline{a})$ if and only if there exists some element $b \in M$ such that $\mathcal{M} \models \psi(\overline{a},\, b)$
    \end{enumerate}

    We say that $\mathcal{M}$ \textit{satisfies} $\phi(\overline{a})$, whenever $\mathcal{M} \models \phi(\overline{a})$.
\end{definition}

With this definition we followed the \hyperref[formula-def]{inductive definition of formulas},
hence the notion of a formula should be unambiguously defined, however there are still some edge cases we need to cover.

% First of all, we should note that Definition \ref{model-satisfaction-def} only accounts for sentences,
% as formulas with free variables are always evaluated at some sequence $\overline{a} = \left<a_1,\ldots,\, a_n\right>$.
% Secondly, a formula might not always have the same free variables as its subformulas, since quantifiers can bind variables which are free in a subformula.
% 
% This proposition is not needed since we require the variables v1,...,vn to be free in the definition of model satisfaction.
%
% \begin{proposition}\cite[Proposition 1.3.16]{Cha90}
%     Let $\mathcal{M} = \left(M,\, f^{\mathcal{M}},\, R^{\mathcal{M}},\, c^{\mathcal{M}}\right)$ be an $\mathcal{L}$-structure.
%     Then the following statements hold:
%     \begin{enumerate}
%         \item Let $t(v_0,\ldots,\, v_p)$ be a term dependent on the variables $v_0,\ldots,\, v_p$ and let $\overline{x} = \left<x_0,\ldots,\, x_q\right>$ and $\overline{y} = \left<y_0,\ldots,\, y_r\right>$ be sequences in $M$,
%         such that $p \leq q$, $p \leq r$ and $x_i = y_i$ whenever $v_i$ is a variable of $t$.
%         Then $$t(\overline{x}) = t(\overline{y}).$$
%         \item Let $\phi$ be a formula in $\mathcal{L}$ with free and bound variables among $v_0,\ldots,\, v_p$ and let $\overline{x} = \left<x_0,\ldots,\, x_q\right>$ and $\overline{y} = \left<y_0,\ldots,\, y_r\right>$ be sequences in $M$,
%         such that $p \leq q$, $p \leq r$ and $x_i = y_i$ whenever $v_i$ is a variable of $t$.
%         Then $$\mathcal{M} \models \phi(\overline{x}) \quad \text{if and only if} \quad \mathcal{M} \models \phi(\overline{y}).$$
%     \end{enumerate}
% \end{proposition}

\begin{theorem}\cite[Proposition 1.3.16]{Cha90}
    Let $\mathcal{M} = \left(M,\, f^{\mathcal{M}},\, R^{\mathcal{M}},\, c^{\mathcal{M}}\right)$ be an $\mathcal{L}$-structure.

    Let $\phi(v_0,\ldots,\, v_p)$ be a formula in $\mathcal{L}$ and let $t_1(v_0,\ldots,\, v_p),\ldots,\, t_p(v_0,\ldots,\, v_p)$ be terms, 
    such that none of the variables of the $t_i$s occur bound in $\phi$.

    Now let $\overline{x} = \left<x_0,\ldots,\, x_p\right>$ be a sequence in $M$ and let $\phi(t_0,\ldots,\, t_p)$ be the formula in $\mathcal{L}$,
    where each variable $v_i$ is substituted with the corresponding term $t_i$ for $i = 0,\ldots,\, p$.
    Then $$\mathcal{M} \models \big(\phi(t_0,\ldots,\, t_p)\big)(\overline{x}) \quad \text{if and only if} \quad \mathcal{M} \models  \phi\big(t_0(\overline{x}) ,\ldots,\, t_p(\overline{x})\big).$$
\end{theorem}

%%% TODO %%%
% Additional properties of formula satisfaction
% Semantical consequence
% Add examples of structures

\subsection{Theories}
\begin{definition}[Theory]\cite[\S.1.2]{Mar02}\cite[\S 1.4]{Cha90}
    We call a set $T$ of sentences in a language $\mathcal{L}$ a \emph{theory} in $\mathcal{L}$.
    Further, we say that an $\mathcal{L}$-structure $\mathcal{M}$ is a \emph{model} of $T$,
    if $\mathcal{M} \models \phi$ for all sentences $\phi \in T$.

    A theory $T$ is said to be \emph{closed} if it is closed under syntactic consequence $\models$.
    Additionally, $T$ is called \emph{complete} if and only if its set of consequences is maximally consistent.

    Since $T$ is a set of sentences, the notions of a \emph{subtheory} and an \emph{extension} of a theory are defined as usual.
\end{definition}

\section{The LÃ¶wenheim-Skolem Theorem}

We now explore the completeness and compactness regarding the models of a given theory.
This bridges the gap between syntax and semantics and as such
the \hyperref[completeness-thm]{Extended Completeness Theorem} tells us that a theory is consistent if and only if it has a model.
The \hyperref[compactness-thm]{Compactness Theorem} states that models of a set of sentences is closed under taking subsets:
if a set of sentences has a model, then every finite subset of that set also has a model.

What we focus on here of course is to prove the namesake of this chapter, the LÃ¶wenheim-Skolem Theorem.
The proof of this is very straightforward and mostly a corollary of the two aforementioned theorems.

\begin{definition}\label{witness-def}\cite[p.61]{Cha90}
    Let $T$ be a set of sentences in a language $\mathcal{L}$ and let $C \subseteq \mathcal{C}$ be a set of constant symbols of $\mathcal{L}$.
    We then call $C$ a \emph{set of witnesses} for $T$ if and only if there exists some constant $c \in C$, such that
    $$T \vdash \big(\exists x \, \phi(x) \rightarrow \phi(c)\big)$$
    holds for all formulas $\phi$ of $\mathcal{L}$ which have at most a single free variable $x$.
\end{definition}

It should be noted that this definition relates entirely to the syntax of $\mathcal{L}$, it does not have anything to do with $\mathcal{L}$-structures as is.
Hence the expression $\phi(c)$ also means that we have replaced all free occurrences of $x$ in $\phi(x)$ by the constant $c$.
It is \emph{not} the evaluation of a formula as seen in Definition \ref{model-satisfaction-def}.

Definition \ref{witness-def} is quite technical and also very catered to the needs of our proofs.
We use it mainly in the following two lemmata, the proofs of which are quite lengthy and tedious as a result.
This is the heavy lifting we have to do before applying Lemmata \ref{completeness-lemma-1} and \ref{completeness-lemma-2} in the proofs of Theorems \ref{completeness-thm} and \ref{compactness-thm}.
Those proofs are in turn comparatively straightforward, the most of the complexity is contained in the lemmata.

\begin{lemma}\label{completeness-lemma-1}\cite[Lemma 2.1.1]{Cha90}
    Let $T$ be a consistent set of sentences of a language $\mathcal{L}$ and   
    let $C$ be a set of new constant symbols not in $\mathcal{L}$ and of power $\left\lvert C \right\rvert = \left\lVert \mathcal{L} \right\rVert$.
    Then let $\overline{\mathcal{L}} = \mathcal{L} \cup C$ be the simple expansion of $\mathcal{L}$ formed by adding $C$.
    
    Then $T$ can be expanded to a consistent set of sentences $\overline{T}$ in $\overline{\mathcal{L}}$, which has $C$ as a set of witnesses in $\overline{\mathcal{L}}$.
\end{lemma}

\begin{proof}
    We will first define the set $C$ with cardinality $\left\lVert \mathcal{L} \right\rVert$.
    Then, similarly to how we did in the proof of Theorem \ref{lindenbaums-theorem}, 
    we define a sequence of consistent terms $T_\xi$ based on the elements of $C$ and show that the desired set of sentences $\overline{T}$ is the union $\bigcup_{\xi < \alpha} T_\xi$.

    Let $\alpha$ be the cardinal $\left\lVert \mathcal{L}\right\rVert$.
    Then, for each cardinal $\beta < \alpha$ we let $c_\beta$ be a constant symbol, 
    such that $c_\beta \neq c_\gamma$ holds for all cardinals $\gamma$ where $\beta < \gamma < \alpha$.
    We can now define set $C = \left\{c_\beta \,\vert\, \beta < \alpha\right\}$ 
    and let $\overline{\mathcal{L}}$ be the simple extension $\overline{\mathcal{L}} = \mathcal{L} \cup C$.

    Since $\left\lVert \mathcal{L}\right\rVert$ is at least countably infinite by the \hyperref[language-def]{definition of the power of a language},
    we have that $\left\lVert \overline{\mathcal{L}}\right\rVert = \alpha$.
    Further, since $\alpha$ is also an ordinal, 
    we can define the sequence $\left\{\phi_\xi \, \vert \, \xi < \alpha\right\}$ of all formulas $\phi$ in $\overline{\mathcal{L}}$ which have at most one free variable.

    We now inductively define another sequence
    $$T = T_0 \subset T_1 \subset \cdots \subset T_\xi \subset \cdots,$$
    of sets of sentences together with a sequence $\left(d_\xi \, \vert \, \xi < \alpha\right)$ of constants in $C$,
    such that these satisfy the following properties:
    \begin{enumerate}[label=(\roman*)]
        \item for each $\xi$, the set $T_\xi$ is consistent in $\overline{\mathcal{L}}$;
        \item if $\xi$ is a successor ordinal $\xi = \eta + 1$, 
        then $T_\xi = T_\eta \cup \left\{\exists x_\eta \, \phi_\eta(x_\eta) \rightarrow \phi_\eta(d_\eta)\right\}$,
        where $x_\eta$ is the free variable of $\phi_\eta$ if it exists and an arbitrary variable $v$ otherwise;
        \item if $\xi$ is a non-zero limit ordinal,
        then $T_\xi = \bigcup_{\eta < \xi} T_\eta$.
    \end{enumerate}

    Assume now that we have defined $T_\eta$ as above.
    We show that $T_\zeta$ is consistent for $\zeta = \eta + 1$.

    Firstly we note that $T_\eta$ contains a strictly lesser than $\alpha$ amount of sentences which are not valid formulas in the original language $\mathcal{L}$.
    These are all sentences which include symbols from $C$.
    Secondly, observe that each of these sentences only contain a finite number of constant symbols from $C$.
    Because of these two assertions, we can assume that there exists some constant $d_\eta$ in the sequence $\left(d_\xi \, \vert \, \xi < \alpha\right)$,
    which has not previously occurred in any of the $T_\xi$, for $\xi < \zeta$.

    Now let 
    $$T_\zeta = T_\eta \cup \left\{\exists x_\eta \, \phi_\eta(x_\eta) \rightarrow \phi_\eta(d_\eta)\right\}$$
    and we assume that $T_\zeta$ is inconsistent in order to derive a contradiction.
    By Proposition \ref{consistency-prop}, this means that $$T_\eta \vdash \lnot \big(\exists x_\eta \, \phi_\eta(x_\eta) \rightarrow \phi_\eta(d_\eta)\big).$$
    Then, using that $\phi \vee \psi$ and $\phi \rightarrow \psi$ are defined as $\lnot \left(\lnot \phi \wedge \lnot \psi\right)$ and $\left(\lnot \phi \vee \psi\right)$ respectively,
    we have that
    \begin{align*}
             & T_\eta \vdash \lnot \big(\exists x_\eta \, \phi_\eta(x_\eta) \rightarrow \phi_\eta(d_\eta)\big) \\
        \iff & T_\eta \vdash \lnot \big(\lnot\left(\exists x_\eta \, \phi_\eta(x_\eta)\right) \vee \phi_\eta(d_\eta)\big) \\
        \iff & T_\eta \vdash \exists x_\eta \, \phi_\eta(x_\eta) \wedge \lnot \, \phi_\eta(d_\eta).
    \end{align*}
    Since $d_\eta$ does not occur in $T_\eta$, we can utilize the \hyperref[generalization-rule]{Rule of Generalization} in the last statement and obtain 
    $$T_\eta \vdash \forall x_\eta \, \big(\exists x_\eta \, \phi_\eta(x_\eta) \wedge \lnot \, \phi_\eta(x_\eta)\big)$$
    which is a more general formulation of 
    $$T_\eta \vdash \big(\exists x_\eta \, \phi_\eta(x_\eta)\big) \wedge \lnot \big(\exists x_\eta \, \phi_\eta(x_\eta)\big).$$
    This is clearly a contradiction and hence $T_\zeta$ must be consistent.

    We now assume that $\zeta$ is a limit ordinal and that $T_\eta$ is properly defined for all $\eta <\zeta$.
    Then, since each $T_\eta$ is consistent, so is $T_\zeta = \bigcup_{\eta < \zeta} T_\eta$.
    As such $\left(T_\xi \, \vert \, \xi < \alpha\right)$ is a well-defined sequence.

    We now let $\overline{T}$ be the union $\bigcup_{\xi < \alpha} T_\xi$.
    Then, as we just showed in the definition of $\left(T_\xi \, \vert \, \xi < \alpha\right)$,
    $\overline{T}$ is made up of only consistent sets of sentences and is therefore also consistent in $\overline{\mathcal{L}}$,
    as an extension of $T$.

    Finally we show that $C$ is the set of witnesses of $\overline{T}$ in $\overline{\mathcal{L}}$.
    Suppose that $\phi$ is a formula with at most one free variable $x$ in $\overline{\mathcal{L}}$.
    We can assume that $\phi$ is $\phi_\xi$ and that $x = x_\xi$.
    As such the sentence $$\exists x_\xi \, \phi_\xi(x_\xi) \rightarrow \phi_\xi(d_\xi)$$ is a member of $T_{\xi + 1}$ and thus also of $\overline{T}$.
    Since the formula $\phi$ was arbitrary, the set $C$ is indeed a set of witnesses for $\overline{T}$. 
\end{proof}

\begin{lemma}\label{completeness-lemma-2}\cite[Lemma 2.1.2]{Cha90}
    Let $T$ be a consistent set of sentences and let $C$ be a set of witnesses for $T$ in $\mathcal{L}$.
    Then there exists a model $\mathcal{M}$ satisfying the theory of $T$, such that every element of $\mathcal{M}$ is an interpretation of a constant $c \in C$.
\end{lemma} 

\begin{proof}
    Suppose that $T'$ is an extension of $T$, i.e. $T \subset T'$.
    Then $T'$ also has $C$ for a set of witnesses in $\mathcal{L}$ and if some $\mathcal{L}$-structure is a model of $T'$ it is also a model of $T$.
    Because of this and since by Theorem \ref{lindenbaums-theorem} we can always extend a consistent set of sentences to a maximally consistent one,
    we can assume without loss of generality that the set $T$ is maximally consistent.

    Let $c,\, d \in C$ be two constants. 
    We define a relation $c \sim d$ if and only if the formula $c = d$ is in $T$.
    This is indeed an equivalence relation.
    Since $T$ is maximally consistent we have that the relation $\sim$ satisfies
    \begin{enumerate}[label=(\roman*)]
        \item $c \sim c$,
        \item if $c \sim d$ and $d \sim e$, then $c \sim e$,
        \item if $c \sim d$, then $d \sim c$
    \end{enumerate}
    for all $c,\, d,\, e \in C$.
    For elements $c \in C$ we denote the equivalence class of $c$ by
    $$\tilde{c} = \left\{d \in C \,\vert\,c \sim d\right\}.$$

    We now get to constructing an $\mathcal{L}$-structure $\mathcal{M}$ with the underlying set $A$,
    the elements of which are the equivalence classes $\tilde{c}$ for $c \in C$.
    We construct this structure in steps and then show that it is actually a model of $T$.
    \begin{enumerate}
        \item \label{lemma-proof-step-1} \textbf{Interpretations of relations} $R \in \mathcal{R}$
        
        For each $n_R$-ary relation symbol $R$ in $\mathcal{L}$,
        we define a relation $R' \subseteq C^{n_R}$ on the set $C$ such that
        \begin{equation}\label{congruence-eq}
            \left<c_1,\cdots,\,c_{n_R}\right> \in R' \iff R(c_1,\cdots,\,c_{n_R}) \in T.
        \end{equation}
        We have that $\sim$ is a \emph{congruence relation} for the relation $R'$.
        This means that if we have $\left<c_1,\cdots,\,c_{n_R}\right> \in R'$ and $c_i \sim d_i$ for elements $c_i,\, d_i, \in C,\, i = 1,\cdots,\, n_{n_R}$, 
        it follows that $\left<d_1,\cdots,\,d_{n_R}\right> \in R'$.
        
        More formally the \hyperref[identity-axioms]{Identity Axioms} ensure that
        $$\vdash R(c_1,\cdots,\,c_{n_R}) \wedge (c_1 = d_1) \wedge \cdots \wedge (c_{n_R} = d_{n_R}) \rightarrow R(d_1,\cdots,\,d_{n_R}).$$

        We now define the interpretation $R^\mathcal{M}$ of $R$ on $A$ by
        $$\left<\tilde{c}_1,\cdots,\,\tilde{c}_{n_R}\right> \in R^\mathcal{M} \iff R(c_1,\cdots,\,c_{n_R}) \in T$$
        and have by \eqref{congruence-eq} that $R^\mathcal{M}$ is not dependent on the choice of representative $c$ for each equivalence class $\tilde{c}$.

        \item \label{lemma-proof-step-2} \textbf{Interpretations of constants} $d \in \mathcal{C}$
        
        Let $d$ be a constant symbol of $\mathcal{L}$.
        It then follows from first-order logic that 
        $$\vdash \exists v \, (d = v)$$
        and since $T$ is maximally consistent this also means that $\big(\exists v \, (d = v)\big) \in T$.
        
        Further, since $C$ is a set of witnesses in $T$, there exists a constant $c \in C$, such that $(d = c) \in T$.
        Hence we choose the interpretation of $d$ in $\mathcal{M}$ to be the equivalence class $\tilde{c}$.
        In the case that $d \in C$, it of course follows that the interpretation of $d$ is $\tilde{d}$.

        The constant $c$ might not be unique, however the equivalence class is.
        Using the Identity Axioms we have that
        $$\vdash (d = c \wedge d = c') \rightarrow c = c'$$
        such that the interpretation of $d$ is not dependent on the representative of the equivalence class.

        \item \label{lemma-proof-step-3}\textbf{Interpretations of functions} $f \in \mathcal{F}$
        
        We proceed similarly to steps \ref{lemma-proof-step-1} and \ref{lemma-proof-step-2}.
        We have that
        $$\vdash \exists v\, f(c_1,\ldots,\, c_{n_f}) = v$$
        holds by first order logic for constants $c_1,\ldots,\, c_{n_f} \in C$ and a function $f \in \mathcal{F}$.
        Then, as $T$ has witnesses in $C$, it follows that $\big(f(c_1,\ldots,\, c_{n_f}) = c\big) \in T$ for some constant $c \in C$.
        By the Identity Axioms
        \begin{multline}\label{function-congruence-eq}
            \vdash f(c_1,\cdots,\,c_{n_f}) = c \wedge (c_1 = d_1) \wedge \cdots \wedge (c_{n_R} = d_{n_R}) \wedge (c = d) \\
            \rightarrow f(d_1,\cdots,\,d_{n_f})= d.
        \end{multline}
        and as such the value of the function is unique with respect to the equivalence classes of $C$.

        Finally, we define the interpretation of $f$ in $\mathcal{M}$ by 
        $$f^\mathcal{M}(\tilde{c}_1,\cdots,\,\tilde{c}_{n_f}) = \tilde{c} \iff \big(f(c_1,\cdots,\,c_{n_f}) = c\big) \in T.$$
    \end{enumerate}
    We have constructed an $\mathcal{L}$-structure $\mathcal{M}$,
    of which the underlying set $A$ consists entirely out of the equivalence classes $\tilde{c}$ of $C$ with respect to the relation $\sim$.
    As such every $\tilde{c} \in A$ is the interpretation of some constant symbol $c \in C$.

    We now show that $\mathcal{M}$ is indeed a model of $T$.
    Let $t$ be a term in $\mathcal{L}$ with no free variables, 
    we show that 
    \begin{equation}\label{lemma-proof-term-model}
        \mathcal{M} \models t = c \iff (t = c) \in T.
    \end{equation}

    By Definition \ref{term-def} a term without free variables is either of the form $t = d$ for a constant $d \in \mathcal{C}$ or $t = f(t_1,\ldots,\, t_{f_n})$ for a function $f \in \mathcal{F}$ and terms $t_1,\ldots,\, t_{f_n}$.
    We have that \eqref{lemma-proof-term-model} already holds for $t = d$ and $t = f(d_1,\ldots,\, d_{f_n})$ by steps \ref{lemma-proof-step-2} and \ref{lemma-proof-step-3} above,
    where $d,\, d_1,\ldots,\, d_{f_n} \in \mathcal{C}$ are constants.
    Additionally \eqref{function-congruence-eq} assures us that all functions are well defined in $\mathcal{M}$, 
    meaning that we can extent \eqref{lemma-proof-term-model} to hold for all terms $t$.

    We now also have that
    \begin{align}
        \mathcal{M} \models t_1 = t_2  &\iff (t_1 = t_2) \in T, \label{lemma-proof-term-eqality}\\
        \mathcal{M} \models R^\mathcal{M}\left(t_1,\cdots,\,t_{n_R}\right) &\iff R(t_1,\cdots,\,t_{n_R}) \in T \ \label{lemma-proof-term-relation}
    \end{align}
    for bound terms $t_1,\, t_2, \ldots,\, t_{n_R}$ following from step \ref{lemma-proof-step-1} above and the fact that $T$ has witnesses in $C$.

    With this we have covered model satisfaction for all atomic sentences in $\mathcal{L}$.
    We now proceed with proving 
    \begin{equation}\label{lemma-proof-forumula}
        \mathcal{M} \models \phi \iff \phi \in T
    \end{equation}
    for sentences $\phi$ using induction on Definition \ref{formula-def}.
    For sentences $\phi,\, \psi \in \mathcal{L}$ it follows from Definition \ref{formula-def} that
    \begin{align*}
        \mathcal{M} \models \lnot\, \phi &\iff (\lnot\, \phi) \in T \\
        \mathcal{M} \models \phi \wedge \psi &\iff (\phi \wedge \psi) \in T.
    \end{align*}
    Now assume that $\phi$ is the sentence $\exists v\, \psi(v)$ and that $\mathcal{M} \models \phi$.
    Then there exists some $\tilde{c} \in A$ such that $\mathcal{M} \models \psi(\tilde{c})$.
    
    Due to how we defined the model $\mathcal{M}$ this means that there also exists some constant symbol $c \in C$ in $\mathcal{L}$,
    such that $\mathcal{M} \models \psi(c)$.
    This in turn, also by construction, means that $\psi(c) \in T$.
    Note that by $\psi(c)$ we mean the sentence in $\mathcal{L}$ where all occurrences of $v$ have been replaced by the constant $c$ and \emph{not} the evaluation of $\phi$ with respect to $c$.
    
    As such we have that
    $$\vdash \psi(c) \rightarrow \exists v\, \psi(v)$$
    and since $\phi$ \emph{is} $\exists v\, \psi(v)$ also $\phi \in T$.

    Now assume that $\phi \in T$, where again $\phi$ is $\exists v\, \psi(v)$, we want to prove that $\mathcal{M}$ satisfies $\phi$.
    Because $C$ is a set of witnesses to $T$ this means that 
    $$T \vdash \exists v\, \psi(v) \rightarrow \psi(c).$$
    The set $T$ is maximally consistent and hence $\psi(c) \in T$ and $\mathcal{M} \models \psi(c)$.
    Therefore there exists an equivalence class $\tilde{c} \in A$ such that $\mathcal{M} \models \psi(\tilde{c})$.
    
    Finally we have that
    $$\mathcal{M} \models \phi$$
    and hence $\mathcal{M}$ is a model of the theory $T$.
\end{proof}

\begin{theorem}[Extended Completeness Theorem]\label{completeness-thm}\cite[Theorem 1.3.21]{Cha90}
    Let $\Sigma$ be a set of sentences in $\mathcal{L}$.
    Then $\Sigma$ is consistent if and only if $\Sigma$ has a model.
\end{theorem}

\begin{proof}
    %Show that model -> consistency
    Let $\mathcal{M}$ be a model of $\Sigma$ and assume towards a contradiction that $\Sigma$ is inconsistent.
    Then by Proposition , there exits a sentence $\phi \in \Sigma$, such that $\Sigma \vdash \lnot\phi$.
    This also means that $\mathcal{M} \models \phi$ and $\mathcal{M} \models \lnot \phi$.
    However this is a violation of Definition \ref{model-satisfaction-def} and therefore $\Sigma$ must be consistent.

    We now assume that $\Sigma$ is a consistent set of sentences and want to show that a model $\mathcal{M}$ of $\Sigma$ exists.
    Consider extension $\overline{\Sigma}$ and $\overline{\mathcal{L}}$ of $\Sigma$ and $\mathcal{L}$ respectively,
    such that $\overline{\mathcal{L}}$ has witnesses in $\overline{\Sigma}$, which is possible by Lemma \ref{completeness-lemma-1}.

    Using Lemma \ref{completeness-lemma-2} we construct a model $\mathcal{N}$ of $\overline{\Sigma}$.
    Now, $\mathcal{N}$ is an $\overline{\mathcal{L}}$-structure.
    Hence we let $\mathcal{M}$ be the restriction of $\mathcal{N}$ to $\mathcal{L}$.
    Because $\Sigma$ does not contain any sentences of $\overline{\mathcal{L}}$,
    we have that $\mathcal{M}$ is an $\mathcal{L}$-structure and a model of $\Sigma$.
\end{proof}

\begin{theorem}[Compactness Theorem]\label{compactness-thm}\cite[Theorem 1.3.22]{Cha90}
    A set of sentences $\Sigma$ has a model if and only if every finite subset of $\Sigma$ has a model.
\end{theorem}

\begin{proof}
    By Proposition \ref{consistency-prop} the set $\Sigma$ is consistent if and only if every finite subset of $\Sigma$ is consistent.
    This combined with Theorem \ref{completeness-thm} means that if every finite subset of $\Sigma$ has a model, it is also consistent.
    Hence $\Sigma$ itself is consistent and has a model.
    By that same line of reasoning every finite subset of $\Sigma$ has a model if $\Sigma$ is consistent.
\end{proof}

We now come to our final theorem and the namesake of this section.
Assume we have a theory $T$ in a language $\mathcal{L}$.
The LÃ¶wenheim-Skolem Theorem then relates the power of models of a $T$ to the power of $\mathcal{L}$ itself.

We treat the theorem in two separate parts.
The Downward LÃ¶wenheim-Skolem Theorem assures us that there exist models of $T$ with power \emph{at most} $\left\lVert \mathcal{L}\right\rVert$.
As such, if we have a model of $T$ with cardinality greater than $\left\lVert \mathcal{L} \right\rVert$, 
we can \emph{move down} and know that a model with lower power exists.

Similarly, the Upward LÃ¶wenheim-Skolem Theorem states that if $T$ has an infinite model, it in fact has models of arbitrary infinite cardinality.
This means that if we are able to model $T$ using, say, the natural numbers as the underlying set,
we are also know that that an uncountable model of $T$ exists.
This is the property we later make use of in the proof on Theorem \ref{main-thm}.
As such the the Upward LÃ¶wenheim-Skolem Theorem allows us to \emph{move up} in cardinality for models of $T$.

\begin{theorem}[Downward LÃ¶wenheim-Skolem Theorem]\label{down-lowenheim-skolem}\cite[Corollary 2.1.4]{Cha90}
    Every consistent theory $T$ in a language $\mathcal{L}$ has a model of power at most $\left\lVert \mathcal{L} \right\rVert$.
\end{theorem}

\begin{proof}
    We modify the proof of Theorem \ref{completeness-thm} using arguments from Lemma \ref{completeness-lemma-1}.

    Let $\left\lVert \mathcal{L} \right\rVert = \alpha$.
    We again consider the simple extension of $\mathcal{L}$ by a set of constants, such that $\overline{\mathcal{L}} = \mathcal{L} \cup C$.
    Then by Lemma \ref{completeness-lemma-1} $T$ can be expanded to a consistent set of sentences $\overline{T}$ in $\overline{\mathcal{L}}$, 
    such that $\overline{T}$ has $C$ as a set of witnesses.
    As in the proof of Lemma \ref{completeness-lemma-1} we can construct this set of constants $C$ in a way where the cardinality of $C$ is $\left\lvert C\right\rvert = \alpha$.
    This means that the power of $\overline{\mathcal{L}}$ also is $\alpha$.

    By Lemma \ref{completeness-lemma-2} the set $\overline{T}$ has a model $\mathcal{N}$ in $\overline{\mathcal{L}}$.
    Hence we consider the model $\mathcal{M}$ which is the restriction of $\mathcal{N}$ to $\mathcal{L}$.
    We have already shown in the proof of Theorem \ref{completeness-thm} that $\mathcal{M}$ is indeed a model of $T$.
    Further, since $\left\lVert \mathcal{L} \right\rVert = \alpha$ we have that $\mathcal{M}$ has power of at most $\alpha$.
\end{proof}

\begin{theorem}[Upward LÃ¶wenheim-Skolem Theorem]\label{up-lowenheim-skolem}\cite[Corollary 2.1.6]{Cha90}
    If a theory $T$ has infinite models, then it has infinite models of any given power $\alpha \geq \left\lVert \mathcal{L} \right\rVert$.
\end{theorem}

\begin{proof}
    Consider a set $C = \left\{c_\xi \,\vert\, \xi < \alpha\right\}$ of constant symbols $c_\xi$ which are not part of the language $\mathcal{L}$.
    We define a set of sentences $\Sigma$ by
    $$\Sigma = T \cup \left\{\lnot (c_\xi = c_\zeta) \,\vert\, \xi < \zeta < \alpha\right\}.$$
    Further, note that every finite subset $\Sigma' \subset \Sigma$ also only contains a finite number of constants $c_\xi$.
    Hence every infinite model $\mathcal{M}$ of $T$ can be extended to a model $\mathcal{M}'$ of $\Sigma'$.

    It then follows from Theorem \ref{compactness-thm} that $\Sigma$ itself also has a model $\mathcal{N}$.
    By the \hyperref[down-lowenheim-skolem]{Downward LÃ¶wenheim-Skolem Theorem} this model   $\mathcal{N}$ has power of at most
    $$\left\lVert \mathcal{L} \cup \left\{c_\xi \,\vert\, \xi < \alpha\right\}\right\rVert = \alpha.$$
    However, the underlying set $N$ of $\mathcal{N}$ must have unique interpretations for each symbol in $\left\{c_\xi \,\vert\, \xi < \alpha\right\}$.
    As such we have that the cardinality of $N$ satisfies
    $$\alpha \leq \left\lvert N\right\rvert$$
    and indeed see that $\mathcal{N}$ exactly has power $\left\lvert N\right\rvert$.
\end{proof}

Lastly it should be pointed out, that we do indeed use the Axiom of Choice in the last proof.
They way we arrange the constants in a sequence is not always possible without \textbf{AC}.
Additionally the comparability of sets is not given in \textbf{ZF}, which is the property that $\left\lvert X\right\rvert \leq \left\lvert Y\right\rvert$ or $\left\lvert X\right\rvert \geq \left\lvert Y\right\rvert$ holds for all set $X$ and $Y$.
This is something the theorem implicitly assumes in its formulation.
\end{document}